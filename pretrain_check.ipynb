{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from SpeakerNet import SpeakerNet\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/K_NeXt_TDNN.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "BATCH_SIZE = config['PARAMS']['BATCH_SIZE']\n",
    "BASE_LR = float(config['PARAMS']['BASE_LR'])\n",
    "NUM_WORKER = config['PARAMS']['NUM_WORKER']\n",
    "CHANNEL_SIZE = config['PARAMS']['CHANNEL_SIZE']\n",
    "EMBEDDING_SIZE = config['PARAMS']['EMBEDDING_SIZE']\n",
    "MAX_FRAME = config['PARAMS']['MAX_FRAME']\n",
    "SAMPLING_RATE = config['PARAMS']['SAMPLING_RATE']\n",
    "MAX_EPOCH = config['PARAMS']['MAX_EPOCH']\n",
    "DEVICE = 'cpu' #config['PARAMS']['DEVICE']\n",
    "BASE_PATH = config['PARAMS']['BASE_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = importlib.import_module('preprocessing.mel_transform').__getattribute__(\"feature_extractor\")\n",
    "feature_extractor = feature_extractor(*config['FEATURE_EXTRACTOR'].values()).to(DEVICE)\n",
    "\n",
    "spec_aug = importlib.import_module('preprocessing.spec_aug').__getattribute__(\"spec_aug\")\n",
    "spec_aug = spec_aug(*config['SPEC_AUG'].values()).to(DEVICE)\n",
    "\n",
    "model_cfg = config['MODEL']\n",
    "model = importlib.import_module('models.NeXt_TDNN').__getattribute__(\"MainModel\")\n",
    "model =  model(\n",
    "    depths = model_cfg['depths'], \n",
    "    dims = model_cfg['dims'],\n",
    "    kernel_size = model_cfg['kernel_size'],\n",
    "    block = model_cfg['block']\n",
    ").to(DEVICE)\n",
    "\n",
    "aggregation = importlib.import_module('aggregation.vap_bn_tanh_fc_bn').__getattribute__(\"Aggregation\")\n",
    "aggregation = aggregation(*config['AGGREGATION'].values()).to(DEVICE)\n",
    "\n",
    "loss_function = importlib.import_module(\"loss.aamsoftmax\").__getattribute__(\"LossFunction\")\n",
    "loss_function = loss_function(*config['LOSS'].values())\n",
    "\n",
    "speaker_net = SpeakerNet(feature_extractor = feature_extractor,\n",
    "                       spec_aug = spec_aug, \n",
    "                       model = model,\n",
    "                       aggregation=aggregation,\n",
    "                       loss_function = loss_function).to(DEVICE)\n",
    "\n",
    "optimizer = importlib.import_module(\"optimizer.\" + 'adamw').__getattribute__(\"Optimizer\")\n",
    "optimizer = optimizer(speaker_net.parameters(), lr= BASE_LR*BATCH_SIZE, weight_decay = 0.01,)    \n",
    "\n",
    "scheduler = importlib.import_module(\"scheduler.\" + 'steplr').__getattribute__(\"Scheduler\")\n",
    "scheduler = scheduler(optimizer, step_size = 10, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_param_mmac(speaker_net, int(160*300 + 240), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_vram import check_vram\n",
    "\n",
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_net.eval()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_stack=True,profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        speaker_net(torch.randn(24320,).unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "dic = torch.load('./experiments/NeXt_TDNN_light_C192_B1_K65/NeXt_TDNN_light_C192_B1_K65.pt')\n",
    "speaker_net.load_state_dict(dic['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knext\n",
    "dic = torch.load('./experiments/K_NeXt_TDNN/ckpt_5.pt')\n",
    "speaker_net.load_state_dict(dic['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from inference import *\n",
    "\n",
    "test_audio_file = 'KHOtest.wav' ####\n",
    "\n",
    "speaker_net.eval()\n",
    "test_audio = load_audio(test_audio_file, DEVICE)\n",
    "\n",
    "start = time.time()\n",
    "test_emb = speaker_net(test_audio.unsqueeze(0))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
