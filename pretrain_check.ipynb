{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from SpeakerNet import SpeakerNet\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/K_NeXt_TDNN.yaml') as file:\n",
    "#with open('toy.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "BATCH_SIZE = config['PARAMS']['BATCH_SIZE']\n",
    "BASE_LR = float(config['PARAMS']['BASE_LR'])\n",
    "NUM_WORKER = config['PARAMS']['NUM_WORKER']\n",
    "CHANNEL_SIZE = config['PARAMS']['CHANNEL_SIZE']\n",
    "EMBEDDING_SIZE = config['PARAMS']['EMBEDDING_SIZE']\n",
    "MAX_FRAME = config['PARAMS']['MAX_FRAME']\n",
    "SAMPLING_RATE = config['PARAMS']['SAMPLING_RATE']\n",
    "MAX_EPOCH = config['PARAMS']['MAX_EPOCH']\n",
    "DEVICE = 'cpu' #config['PARAMS']['DEVICE']\n",
    "BASE_PATH = config['PARAMS']['BASE_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised AAMSoftmax margin 0.300 scale 40.000\n",
      "⚡ feature_extractor ⚡\n",
      "Mel_Spectrogram(\n",
      "  (pre_emphasis): PreEmphasis()\n",
      "  (mel_spectrogram): MelSpectrogram(\n",
      "    (spectrogram): Spectrogram()\n",
      "    (mel_scale): MelScale()\n",
      "  )\n",
      ")\n",
      "⚡ spec_aug ⚡\n",
      "SpecAugment(\n",
      "  (fm): FrequencyMasking()\n",
      "  (tm): TimeMasking()\n",
      ")\n",
      "⚡ model ⚡\n",
      "NeXtTDNN(\n",
      "  (stem): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(80, 192, kernel_size=(4,), stride=(1,))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): TSConvNeXt_light(\n",
      "        (dwconv): Conv1d(192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (grn): GRN()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (MFA): Sequential(\n",
      "    (0): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      "    (1): LayerNorm()\n",
      "  )\n",
      ")\n",
      "⚡ aggregation ⚡\n",
      "VAP_BN_FC_BN(\n",
      "  (conv_1): Conv1d(576, 72, kernel_size=(1,), stride=(1,))\n",
      "  (conv_2): Conv1d(72, 576, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (tanh): Tanh()\n",
      "  (bn2): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=1152, out_features=192, bias=True)\n",
      "  (bn3): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "⚡ loss ⚡\n",
      "LossFunction(\n",
      "  (ce): CrossEntropyLoss()\n",
      ")\n",
      "Initialised AdamW optimizer\n",
      "Initialised step LR scheduler\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = importlib.import_module('preprocessing.mel_transform').__getattribute__(\"feature_extractor\")\n",
    "feature_extractor = feature_extractor(*config['FEATURE_EXTRACTOR'].values()).to(DEVICE)\n",
    "\n",
    "#fe = feature_extractor(x.to(DEVICE))\n",
    "#print('feature extractor :', fe.shape)\n",
    "\n",
    "spec_aug = importlib.import_module('preprocessing.spec_aug').__getattribute__(\"spec_aug\")\n",
    "spec_aug = spec_aug(*config['SPEC_AUG'].values()).to(DEVICE)\n",
    "\n",
    "#sa = spec_aug(fe)\n",
    "#print('spec aug :', sa.shape)\n",
    "\n",
    "model_cfg = config['MODEL']\n",
    "model = importlib.import_module('models.NeXt_TDNN').__getattribute__(\"MainModel\")\n",
    "model =  model(\n",
    "    depths = model_cfg['depths'], \n",
    "    dims = model_cfg['dims'],\n",
    "    kernel_size = model_cfg['kernel_size'],\n",
    "    block = model_cfg['block']\n",
    ").to(DEVICE)\n",
    "\n",
    "#m = model(sa.to(DEVICE))\n",
    "#print('model :', m.shape)\n",
    "\n",
    "aggregation = importlib.import_module('aggregation.vap_bn_tanh_fc_bn').__getattribute__(\"Aggregation\")\n",
    "aggregation = aggregation(*config['AGGREGATION'].values()).to(DEVICE)\n",
    "\n",
    "#a = aggregation(m).to(DEVICE)\n",
    "#print('aggregation : ', a.shape)\n",
    "\n",
    "loss_function = importlib.import_module(\"loss.aamsoftmax\").__getattribute__(\"LossFunction\")\n",
    "loss_function = loss_function(*config['LOSS'].values())\n",
    "\n",
    "speaker_net = SpeakerNet(feature_extractor = feature_extractor,\n",
    "                       spec_aug = spec_aug, \n",
    "                       model = model,\n",
    "                       aggregation=aggregation,\n",
    "                       loss_function = loss_function).to(DEVICE)\n",
    "\n",
    "optimizer = importlib.import_module(\"optimizer.\" + 'adamw').__getattribute__(\"Optimizer\")\n",
    "optimizer = optimizer(speaker_net.parameters(), lr= BASE_LR*BATCH_SIZE, weight_decay = 0.01,)    \n",
    "\n",
    "scheduler = importlib.import_module(\"scheduler.\" + 'steplr').__getattribute__(\"Scheduler\")\n",
    "scheduler = scheduler(optimizer, step_size = 10, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerNet(\n",
      "  1.63 M, 84.888% Params, 420.52 MMac, 98.346% MACs, \n",
      "  (feature_extractor): Mel_Spectrogram(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (pre_emphasis): PreEmphasis(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (mel_spectrogram): MelSpectrogram(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (spectrogram): Spectrogram(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (mel_scale): MelScale(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (spec_aug): SpecAugment(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (fm): FrequencyMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (tm): TimeMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (model): NeXtTDNN(\n",
      "    1.32 M, 68.832% Params, 395.25 MMac, 92.439% MACs, \n",
      "    (stem): ModuleList(\n",
      "      (0): Sequential(\n",
      "        61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, \n",
      "        (0): Conv1d(61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, 80, 192, kernel_size=(4,), stride=(1,))\n",
      "        (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (stages): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "        (0): TSConvNeXt_light(\n",
      "          308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "          (dwconv): Conv1d(12.67 k, 0.661% Params, 3.79 MMac, 0.886% MACs, 192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "          (norm): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv1): Linear(148.22 k, 7.732% Params, 44.32 MMac, 10.365% MACs, in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(0, 0.000% Params, 229.63 KMac, 0.054% MACs, approximate='none')\n",
      "          (grn): GRN(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv2): Linear(147.65 k, 7.701% Params, 44.15 MMac, 10.325% MACs, in_features=768, out_features=192, bias=True)\n",
      "          (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (MFA): Sequential(\n",
      "      332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, \n",
      "      (0): Conv1d(332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, 576, 576, kernel_size=(1,), stride=(1,))\n",
      "      (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (aggregate): VAP_BN_FC_BN(\n",
      "    307.8 k, 16.055% Params, 25.26 MMac, 5.908% MACs, \n",
      "    (conv_1): Conv1d(41.54 k, 2.167% Params, 12.42 MMac, 2.905% MACs, 576, 72, kernel_size=(1,), stride=(1,))\n",
      "    (conv_2): Conv1d(42.05 k, 2.193% Params, 12.57 MMac, 2.940% MACs, 72, 576, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(144, 0.008% Params, 43.06 KMac, 0.010% MACs, 72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (tanh): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (bn2): BatchNorm1d(2.3 k, 0.120% Params, 2.3 KMac, 0.001% MACs, 1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): Linear(221.38 k, 11.547% Params, 221.38 KMac, 0.052% MACs, in_features=1152, out_features=192, bias=True)\n",
      "    (bn3): BatchNorm1d(384, 0.020% Params, 384.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (loss_function): LossFunction(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (ce): CrossEntropyLoss(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "ptflops: MMac: 427.59, Params: 1.92\n",
      "thop: MMac: 418.415136, Params: 1.627416\n",
      "torchinfo: MMac: 155.27652, Params: 1.917144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('427.59', '1.92', 418.415136, 1.627416, 155.27652, 1.917144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_param_mmac(speaker_net, int(160*300 + 240), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> GPU:0 총 VRAM: 8188.00 MB\n",
      ">> GPU:0 사용 중인 VRAM: 805.69 MB\n",
      ">> GPU:0 남은 VRAM: 7382.31 MB\n"
     ]
    }
   ],
   "source": [
    "from check_vram import check_vram\n",
    "\n",
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_net.eval()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_stack=True,profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        speaker_net(torch.randn(24320,).unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls                                                                      Input Shapes  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                 model_inference        19.65%       3.696ms       100.00%      18.809ms      18.809ms       3.210ms        17.11%      18.763ms      18.763ms           0 b     -15.94 Mb             1                                                                                []  \n",
      "                    aten::conv1d         0.15%      28.400us        12.89%       2.425ms     808.200us      27.000us         0.14%       2.431ms     810.333us     337.50 Kb           0 b             3                              [[1, 192, 150], [192, 1, 65], [192], [], [], [], []]  \n",
      "               aten::convolution         0.28%      52.900us        12.74%       2.396ms     798.733us      40.000us         0.21%       2.404ms     801.333us     337.50 Kb           0 b             3                      [[1, 192, 150], [192, 1, 65], [192], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.79%     149.300us        12.46%       2.343ms     781.100us     122.000us         0.65%       2.364ms     788.000us     337.50 Kb           0 b             3      [[1, 192, 150], [192, 1, 65], [192], [], [], [], [], [], [], [], [], [], []]  \n",
      "        aten::mkldnn_convolution        11.10%       2.087ms        11.20%       2.107ms     702.233us       2.060ms        10.98%       2.117ms     705.667us     337.50 Kb           0 b             3                        [[1, 192, 1, 150], [192, 1, 1, 65], [192], [], [], [], []]  \n",
      "                      aten::stft         0.38%      72.000us         6.37%       1.197ms       1.197ms      49.000us         0.26%       1.189ms       1.189ms     307.20 Kb    -308.00 Kb             1                                       [[1, 24832], [], [], [], [400], [], [], []]  \n",
      "                    aten::conv1d         0.09%      16.300us         5.28%     993.500us     993.500us      18.000us         0.10%     997.000us     997.000us      95.00 Kb           0 b             1                                    [[1, 1, 24321], [1, 1, 2], [], [], [], [], []]  \n",
      "               aten::convolution         0.12%      21.800us         5.20%     977.200us     977.200us      22.000us         0.12%     979.000us     979.000us      95.00 Kb           0 b             1                            [[1, 1, 24321], [1, 1, 2], [], [], [], [], [], [], []]  \n",
      "                  aten::_fft_r2c         4.99%     939.400us         5.16%     971.100us     971.100us     918.000us         4.89%     973.000us     973.000us     307.20 Kb           0 b             1                                                       [[1, 153, 512], [], [], []]  \n",
      "              aten::_convolution         0.33%      62.700us         5.08%     955.400us     955.400us      42.000us         0.22%     957.000us     957.000us      95.00 Kb           0 b             1            [[1, 1, 24321], [1, 1, 2], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "                    aten::conv1d         0.09%      17.800us         4.80%     903.400us     903.400us       8.000us         0.04%     905.000us     905.000us     337.50 Kb           0 b             1                             [[1, 576, 150], [576, 576, 1], [576], [], [], [], []]  \n",
      "               aten::convolution         0.12%      21.900us         4.71%     885.600us     885.600us      32.000us         0.17%     897.000us     897.000us     337.50 Kb           0 b             1                     [[1, 576, 150], [576, 576, 1], [576], [], [], [], [], [], []]  \n",
      "                    aten::linear         0.72%     134.600us         4.69%     883.000us     294.333us      99.000us         0.53%     889.000us     296.333us       1.32 Mb           0 b             3                                                [[1, 150, 192], [768, 192], [768]]  \n",
      "              aten::_convolution         0.22%      40.800us         4.59%     863.700us     863.700us      36.000us         0.19%     865.000us     865.000us     337.50 Kb           0 b             1     [[1, 576, 150], [576, 576, 1], [576], [], [], [], [], [], [], [], [], [], []]  \n",
      "        aten::mkldnn_convolution         4.44%     834.900us         4.49%     844.000us     844.000us     843.000us         4.49%     862.000us     862.000us      95.00 Kb           0 b             1                              [[1, 1, 1, 24321], [1, 1, 1, 2], [], [], [], [], []]  \n",
      "        aten::mkldnn_convolution         4.23%     796.200us         4.26%     801.300us     801.300us     791.000us         4.22%     803.000us     803.000us     337.50 Kb           0 b             1                       [[1, 576, 1, 150], [576, 576, 1, 1], [576], [], [], [], []]  \n",
      "                    aten::linear         0.81%     152.200us         3.63%     682.500us     227.500us     105.000us         0.56%     686.000us     228.667us     337.50 Kb           0 b             3                                                [[1, 150, 768], [192, 768], [192]]  \n",
      "                aten::layer_norm         0.17%      32.100us         3.29%     619.500us     206.500us      34.000us         0.18%     628.000us     209.333us     341.02 Kb           0 b             3                                         [[1, 150, 192], [], [192], [192], [], []]  \n",
      "                     aten::addmm         2.31%     434.100us         3.16%     593.600us     197.867us     417.000us         2.22%     609.000us     203.000us       1.32 Mb       1.32 Mb             3                                           [[768], [150, 192], [192, 768], [], []]  \n",
      "         aten::native_layer_norm         2.25%     423.200us         3.12%     587.400us     195.800us     381.000us         2.03%     594.000us     198.000us     341.02 Kb    -337.50 Kb             3                                             [[1, 150, 192], [], [192], [192], []]  \n",
      "                      aten::gelu         3.02%     568.900us         3.02%     568.900us     189.633us     584.000us         3.11%     584.000us     194.667us       1.32 Mb       1.32 Mb             3                                                               [[1, 150, 768], []]  \n",
      "                        aten::to         0.55%     104.000us         2.22%     416.700us      29.764us     109.000us         0.58%     493.000us      35.214us          56 b           0 b            14                                                              [[], [], [], [], []]  \n",
      "                    aten::conv1d         0.05%       8.500us         2.44%     459.700us     459.700us       7.000us         0.04%     460.000us     460.000us     112.50 Kb           0 b             1                               [[1, 80, 153], [192, 80, 4], [192], [], [], [], []]  \n",
      "                     aten::addmm         1.99%     374.000us         2.35%     442.400us     147.467us     341.000us         1.82%     457.000us     152.333us     337.50 Kb     337.50 Kb             3                                           [[192], [150, 768], [768, 192], [], []]  \n",
      "               aten::convolution         0.17%      32.100us         2.40%     451.200us     451.200us      31.000us         0.17%     453.000us     453.000us     112.50 Kb           0 b             1                       [[1, 80, 153], [192, 80, 4], [192], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.30%      57.100us         2.23%     419.100us     419.100us      36.000us         0.19%     422.000us     422.000us     112.50 Kb     -47.81 Kb             1       [[1, 80, 153], [192, 80, 4], [192], [], [], [], [], [], [], [], [], [], []]  \n",
      "                    aten::conv1d         0.05%       9.800us         2.14%     401.600us     401.600us       7.000us         0.04%     403.000us     403.000us     337.50 Kb           0 b             1                               [[1, 72, 150], [576, 72, 1], [576], [], [], [], []]  \n",
      "               aten::convolution         0.06%      10.700us         2.08%     391.800us     391.800us      13.000us         0.07%     396.000us     396.000us     337.50 Kb           0 b             1                       [[1, 72, 150], [576, 72, 1], [576], [], [], [], [], [], []]  \n",
      "                  aten::_to_copy         1.47%     277.400us         1.66%     312.700us      22.336us     264.000us         1.41%     384.000us      27.429us          56 b           0 b            14                                                      [[], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.21%      40.400us         2.03%     381.100us     381.100us      22.000us         0.12%     383.000us     383.000us     337.50 Kb           0 b             1       [[1, 72, 150], [576, 72, 1], [576], [], [], [], [], [], [], [], [], [], []]  \n",
      "                    aten::conv1d         0.04%       7.500us         1.98%     372.300us     372.300us       7.000us         0.04%     373.000us     373.000us      42.19 Kb           0 b             1                               [[1, 576, 150], [72, 576, 1], [72], [], [], [], []]  \n",
      "               aten::convolution         0.06%      10.700us         1.94%     364.800us     364.800us      10.000us         0.05%     366.000us     366.000us      42.19 Kb           0 b             1                       [[1, 576, 150], [72, 576, 1], [72], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.14%      26.800us         1.88%     354.100us     354.100us      22.000us         0.12%     356.000us     356.000us      42.19 Kb           0 b             1       [[1, 576, 150], [72, 576, 1], [72], [], [], [], [], [], [], [], [], [], []]  \n",
      "        aten::linalg_vector_norm         1.68%     315.900us         1.68%     315.900us     105.300us     331.000us         1.76%     331.000us     110.333us       9.00 Kb       9.00 Kb             3                                                   [[1, 150, 768], [], [], [], []]  \n",
      "               aten::thnn_conv2d         0.06%      11.100us         1.70%     318.900us     318.900us      29.000us         0.15%     321.000us     321.000us     337.50 Kb           0 b             1                             [[1, 72, 1, 150], [576, 72, 1, 1], [], [576], [], []]  \n",
      "                       aten::mul         1.58%     296.400us         1.58%     296.400us      98.800us     309.000us         1.65%     309.000us     103.000us       1.32 Mb       1.32 Mb             3                                                      [[1, 1, 768], [1, 150, 768]]  \n",
      "        aten::mkldnn_convolution         1.61%     302.700us         1.64%     307.600us     307.600us     297.000us         1.58%     309.000us     309.000us      42.19 Kb           0 b             1                         [[1, 576, 1, 150], [72, 576, 1, 1], [72], [], [], [], []]  \n",
      "                       aten::mul         1.48%     277.500us         1.48%     277.500us      92.500us     295.000us         1.57%     295.000us      98.333us       1.32 Mb       1.32 Mb             3                                                      [[1, 150, 768], [1, 1, 768]]  \n",
      "                       aten::add         1.49%     281.100us         1.49%     281.100us      93.700us     294.000us         1.57%     294.000us      98.000us       1.32 Mb       1.32 Mb             3                                                  [[1, 150, 768], [1, 1, 768], []]  \n",
      "      aten::_slow_conv2d_forward         1.43%     268.900us         1.64%     307.800us     307.800us     231.000us         1.23%     292.000us     292.000us     337.50 Kb           0 b             1                             [[1, 72, 1, 150], [576, 72, 1, 1], [], [576], [], []]  \n",
      "               aten::thnn_conv2d         0.08%      14.900us         1.53%     287.200us     287.200us      10.000us         0.05%     289.000us     289.000us     112.50 Kb           0 b             1                             [[1, 80, 1, 153], [192, 80, 1, 4], [], [192], [], []]  \n",
      "      aten::_slow_conv2d_forward         1.24%     232.600us         1.45%     272.300us     272.300us     227.000us         1.21%     279.000us     279.000us     112.50 Kb    -187.50 Kb             1                             [[1, 80, 1, 153], [192, 80, 1, 4], [], [192], [], []]  \n",
      "                      aten::mean         0.37%      70.100us         1.39%     260.600us      86.867us     103.000us         0.55%     277.000us      92.333us          12 b           4 b             3                                                         [[1, 1, 768], [], [], []]  \n",
      "                    aten::matmul         0.35%      66.000us         1.46%     273.700us     273.700us      38.000us         0.20%     275.000us     275.000us      47.81 Kb           0 b             1                                                        [[1, 153, 257], [257, 80]]  \n",
      "                       aten::pad         0.22%      41.900us         1.44%     270.100us     135.050us      24.000us         0.13%     273.000us     136.500us     192.00 Kb           0 b             2                                                       [[1, 1, 24320], [], [], []]  \n",
      "                       aten::abs         0.12%      22.200us         1.39%     262.200us     262.200us      21.000us         0.11%     265.000us     265.000us     153.60 Kb           0 b             1                                                                   [[1, 257, 153]]  \n",
      "          aten::reflection_pad1d         1.21%     228.200us         1.21%     228.200us     114.100us     249.000us         1.33%     249.000us     124.500us     192.00 Kb     192.00 Kb             2                                                               [[1, 1, 24320], []]  \n",
      "                       aten::abs         0.71%     132.900us         1.20%     226.200us     226.200us     107.000us         0.57%     229.000us     229.000us           0 b           0 b             1                                                    [[1, 257, 153], [1, 257, 153]]  \n",
      "                       aten::pow         1.12%     210.400us         1.13%     211.800us     105.900us     212.000us         1.13%     220.000us     110.000us     675.00 Kb     675.00 Kb             2                                                               [[1, 576, 150], []]  \n",
      "                      aten::mean         0.18%      34.100us         1.15%     216.800us     108.400us      39.000us         0.21%     219.000us     109.500us       1.17 Kb       1.16 Kb             2                                                       [[1, 576, 150], [], [], []]  \n",
      "                     aten::empty         0.44%      82.200us         0.44%      82.200us       1.678us     211.000us         1.12%     211.000us       4.306us       2.03 Mb       2.03 Mb            49                                                          [[], [], [], [], [], []]  \n",
      "                    aten::linear         0.09%      16.100us         0.94%     176.700us     176.700us      15.000us         0.08%     184.000us     184.000us         768 b           0 b             1                                                   [[1, 1152], [192, 1152], [192]]  \n",
      "                       aten::add         0.93%     174.800us         0.93%     174.800us      29.133us     183.000us         0.98%     183.000us      30.500us     675.00 Kb     675.00 Kb             6                                                [[1, 192, 150], [1, 192, 150], []]  \n",
      "                      aten::mean         0.18%      33.500us         0.80%     150.600us      75.300us      63.000us         0.34%     174.000us      87.000us       1.17 Kb       1.17 Kb             2                                                       [[1, 192, 150], [], [], []]  \n",
      "                       aten::add         0.27%      51.100us         0.87%     162.900us      54.300us      45.000us         0.24%     171.000us      57.000us          12 b           0 b             3                                                               [[1, 1, 1], [], []]  \n",
      "                      aten::div_         0.44%      83.100us         1.00%     188.400us      47.100us      40.000us         0.21%     168.000us      42.000us           8 b          -8 b             4                                                                 [[1, 1, 150], []]  \n",
      "                       aten::bmm         0.86%     161.700us         0.86%     162.100us     162.100us     165.000us         0.88%     167.000us     167.000us      47.81 Kb      47.81 Kb             1                                                     [[1, 153, 257], [1, 257, 80]]  \n",
      "                     aten::copy_         0.73%     138.000us         0.73%     138.000us      46.000us     156.000us         0.83%     156.000us      52.000us           0 b           0 b             3                                                      [[150, 768], [150, 768], []]  \n",
      "                aten::contiguous         0.14%      26.800us         0.78%     145.800us      48.600us      24.000us         0.13%     153.000us      51.000us     337.50 Kb           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                     aten::randn         0.24%      44.400us         0.80%     150.100us     150.100us      36.000us         0.19%     152.000us     152.000us      95.00 Kb           0 b             1                                                              [[], [], [], [], []]  \n",
      "                       aten::sum         0.59%     111.300us         0.61%     115.500us      57.750us     137.000us         0.73%     150.000us      75.000us       4.50 Kb       4.50 Kb             2                                                       [[1, 576, 150], [], [], []]  \n",
      "                       aten::cat         0.66%     124.200us         0.74%     140.100us      70.050us     118.000us         0.63%     147.000us      73.500us     342.00 Kb     342.00 Kb             2                                                                          [[], []]  \n",
      "                aten::batch_norm         0.06%      11.300us         0.71%     133.400us     133.400us      11.000us         0.06%     135.000us     135.000us      42.19 Kb           0 b             1                            [[1, 72, 150], [72], [72], [72], [72], [], [], [], []]  \n",
      "                      aten::div_         0.40%      74.700us         0.83%     156.300us      52.100us      29.000us         0.15%     133.000us      44.333us           8 b          -4 b             3                                                                   [[1, 1, 1], []]  \n",
      "                     aten::addmm         0.62%     116.300us         0.68%     127.100us     127.100us     105.000us         0.56%     133.000us     133.000us         768 b         768 b             1                                           [[192], [1, 1152], [1152, 192], [], []]  \n",
      "                     aten::clone         0.31%      59.200us         0.63%     119.000us      39.667us      40.000us         0.21%     129.000us      43.000us     337.50 Kb           0 b             3                                                               [[1, 150, 192], []]  \n",
      "    aten::_batch_norm_impl_index         0.13%      24.800us         0.65%     122.100us     122.100us      17.000us         0.09%     124.000us     124.000us      42.19 Kb           0 b             1                            [[1, 72, 150], [72], [72], [72], [72], [], [], [], []]  \n",
      "                aten::batch_norm         0.04%       7.700us         0.61%     114.300us     114.300us       8.000us         0.04%     116.000us     116.000us       4.50 Kb           0 b             1                       [[1, 1152], [1152], [1152], [1152], [1152], [], [], [], []]  \n",
      "                       aten::mul         0.53%     100.600us         0.53%     100.600us      50.300us     108.000us         0.58%     108.000us      54.000us     675.00 Kb     675.00 Kb             2                                                    [[1, 576, 150], [1, 576, 150]]  \n",
      "    aten::_batch_norm_impl_index         0.17%      31.800us         0.57%     106.600us     106.600us      15.000us         0.08%     108.000us     108.000us       4.50 Kb           0 b             1                       [[1, 1152], [1152], [1152], [1152], [1152], [], [], [], []]  \n",
      "                       aten::pow         0.49%      92.800us         0.50%      93.900us      93.900us     100.000us         0.53%     106.000us     106.000us     153.60 Kb     153.60 Kb             1                                                               [[1, 257, 153], []]  \n",
      "         aten::native_batch_norm         0.44%      83.200us         0.51%      96.500us      96.500us      77.000us         0.41%     102.000us     102.000us      42.19 Kb        -576 b             1                                [[1, 72, 150], [72], [72], [72], [72], [], [], []]  \n",
      "                aten::batch_norm         0.04%       7.200us         0.41%      77.600us      77.600us       7.000us         0.04%      99.000us      99.000us         768 b           0 b             1                            [[1, 192], [192], [192], [192], [192], [], [], [], []]  \n",
      "                       aten::add         0.45%      84.800us         0.45%      84.800us      28.267us      96.000us         0.51%      96.000us      32.000us       1.32 Mb       1.32 Mb             3                                                [[1, 150, 768], [1, 150, 768], []]  \n",
      "                      aten::mean         0.12%      22.800us         0.50%      93.700us      93.700us      31.000us         0.17%      95.000us      95.000us         320 b         320 b             1                                                        [[1, 80, 153], [], [], []]  \n",
      "                       aten::add         0.10%      19.000us         0.38%      71.000us      35.500us      38.000us         0.20%      93.000us      46.500us       1.17 Kb       1.16 Kb             2                                                             [[1, 1, 150], [], []]  \n",
      "                   aten::normal_         0.47%      88.400us         0.47%      88.400us      88.400us      92.000us         0.49%      92.000us      92.000us           0 b           0 b             1                                                             [[24320], [], [], []]  \n",
      "    aten::_batch_norm_impl_index         0.09%      17.100us         0.37%      70.400us      70.400us      13.000us         0.07%      92.000us      92.000us         768 b           0 b             1                            [[1, 192], [192], [192], [192], [192], [], [], [], []]  \n",
      "         aten::native_batch_norm         0.33%      61.900us         0.39%      73.700us      73.700us      68.000us         0.36%      90.000us      90.000us       4.50 Kb      -9.00 Kb             1                           [[1, 1152], [1152], [1152], [1152], [1152], [], [], []]  \n",
      "                       aten::sum         0.42%      78.300us         0.43%      81.000us      40.500us      71.000us         0.38%      88.000us      44.000us           0 b           0 b             2                                          [[1, 576, 150], [], [], [], [1, 1, 150]]  \n",
      "                         aten::t         0.24%      44.500us         0.41%      76.500us      25.500us      48.000us         0.26%      83.000us      27.667us           0 b           0 b             3                                                                      [[768, 192]]  \n",
      "                   aten::reshape         0.10%      19.500us         0.37%      69.700us      23.233us      19.000us         0.10%      78.000us      26.000us           0 b           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                       aten::mul         0.39%      72.600us         0.39%      72.600us      72.600us      76.000us         0.41%      76.000us      76.000us     306.00 Kb     306.00 Kb             1                                                            [[1, 153, 512], [512]]  \n",
      "                     aten::copy_         0.12%      22.500us         0.12%      22.500us       1.607us      76.000us         0.41%      76.000us       5.429us           0 b           0 b            14                                                                      [[], [], []]  \n",
      "         aten::native_batch_norm         0.22%      41.300us         0.28%      51.800us      51.800us      55.000us         0.29%      75.000us      75.000us         768 b      -1.50 Kb             1                                [[1, 192], [192], [192], [192], [192], [], [], []]  \n",
      "                       aten::add         0.19%      35.200us         0.38%      70.900us      70.900us      26.000us         0.14%      74.000us      74.000us      47.81 Kb      47.81 Kb             1                                                            [[1, 80, 153], [], []]  \n",
      "                   aten::permute         0.28%      52.600us         0.29%      55.200us      18.400us      53.000us         0.28%      74.000us      24.667us           0 b           0 b             3                                                               [[1, 192, 150], []]  \n",
      "                         aten::t         0.14%      25.800us         0.27%      51.000us      17.000us      43.000us         0.23%      74.000us      24.667us           0 b           0 b             3                                                                      [[192, 768]]  \n",
      "                       aten::pow         0.36%      68.200us         0.36%      68.600us      68.600us      68.000us         0.36%      72.000us      72.000us     112.50 Kb     112.50 Kb             1                                                               [[1, 192, 150], []]  \n",
      "                   aten::softmax         0.08%      14.200us         0.35%      65.300us      65.300us      12.000us         0.06%      68.000us      68.000us     337.50 Kb           0 b             1                                                           [[1, 576, 150], [], []]  \n",
      "                     aten::copy_         0.31%      57.400us         0.31%      57.400us      57.400us      65.000us         0.35%      65.000us      65.000us           0 b           0 b             1                                                [[1, 257, 153], [1, 257, 153], []]  \n",
      "                   aten::squeeze         0.20%      38.500us         0.22%      42.100us      10.525us      49.000us         0.26%      63.000us      15.750us           0 b           0 b             4                                                            [[1, 192, 1, 150], []]  \n",
      "                       aten::sub         0.29%      55.200us         0.29%      55.200us      27.600us      62.000us         0.33%      62.000us      31.000us     675.00 Kb     675.00 Kb             2                                                  [[1, 576, 150], [1, 1, 150], []]  \n",
      "                       aten::log         0.30%      56.500us         0.30%      56.500us      56.500us      60.000us         0.32%      60.000us      60.000us      47.81 Kb      47.81 Kb             1                                                                    [[1, 80, 153]]  \n",
      "                      aten::view         0.27%      50.200us         0.27%      50.200us      16.733us      59.000us         0.31%      59.000us      19.667us           0 b           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                    aten::expand         0.21%      38.700us         0.22%      40.500us      10.125us      37.000us         0.20%      58.000us      14.500us           0 b           0 b             4                                                                   [[192], [], []]  \n",
      "                       aten::add         0.29%      54.100us         0.29%      54.100us      54.100us      58.000us         0.31%      58.000us      58.000us     337.50 Kb     337.50 Kb             1                                                     [[1, 576, 150], [576, 1], []]  \n",
      "                       aten::div         0.28%      53.000us         0.28%      53.000us      53.000us      57.000us         0.30%      57.000us      57.000us     337.50 Kb     337.50 Kb             1                                                      [[1, 576, 150], [1, 1, 150]]  \n",
      "                       aten::mul         0.28%      52.000us         0.28%      52.000us      52.000us      56.000us         0.30%      56.000us      56.000us     337.50 Kb     337.50 Kb             1                                                         [[576, 1], [1, 576, 150]]  \n",
      "                  aten::_softmax         0.27%      51.100us         0.27%      51.100us      51.100us      56.000us         0.30%      56.000us      56.000us     337.50 Kb     337.50 Kb             1                                                           [[1, 576, 150], [], []]  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 18.809ms\n",
      "Self CUDA time total: 18.763ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference        19.65%       3.696ms       100.00%      18.809ms      18.809ms       3.210ms        17.11%      18.763ms      18.763ms           0 b     -15.94 Mb             1  \n",
      "                     aten::randn         0.24%      44.400us         0.80%     150.100us     150.100us      36.000us         0.19%     152.000us     152.000us      95.00 Kb           0 b             1  \n",
      "                     aten::empty         0.44%      82.200us         0.44%      82.200us       1.678us     211.000us         1.12%     211.000us       4.306us       2.03 Mb       2.03 Mb            49  \n",
      "                   aten::normal_         0.47%      88.400us         0.47%      88.400us      88.400us      92.000us         0.49%      92.000us      92.000us           0 b           0 b             1  \n",
      "                 aten::unsqueeze         1.07%     200.700us         1.15%     215.900us       9.814us     219.000us         1.17%     293.000us      13.318us           0 b           0 b            22  \n",
      "                aten::as_strided         0.27%      50.300us         0.27%      50.300us       0.762us     254.000us         1.35%     254.000us       3.848us           0 b           0 b            66  \n",
      "                        aten::to         0.57%     107.200us         2.23%     419.900us      19.995us     128.000us         0.68%     512.000us      24.381us          56 b           0 b            21  \n",
      "                       aten::pad         0.22%      41.900us         1.44%     270.100us     135.050us      24.000us         0.13%     273.000us     136.500us     192.00 Kb           0 b             2  \n",
      "          aten::reflection_pad1d         1.21%     228.200us         1.21%     228.200us     114.100us     249.000us         1.33%     249.000us     124.500us     192.00 Kb     192.00 Kb             2  \n",
      "                    aten::conv1d         0.47%      88.300us        29.53%       5.555ms     694.387us      74.000us         0.39%       5.569ms     696.125us       1.23 Mb           0 b             8  \n",
      "               aten::convolution         0.80%     150.100us        29.06%       5.467ms     683.350us     148.000us         0.79%       5.495ms     686.875us       1.23 Mb           0 b             8  \n",
      "              aten::_convolution         2.00%     377.100us        28.27%       5.317ms     664.587us     280.000us         1.49%       5.347ms     668.375us       1.23 Mb     -47.81 Kb             8  \n",
      "        aten::mkldnn_convolution        21.38%       4.021ms        21.58%       4.060ms     676.600us       3.991ms        21.27%       4.091ms     681.833us     812.19 Kb           0 b             6  \n",
      "               aten::as_strided_         0.09%      16.600us         0.09%      16.600us       1.844us      61.000us         0.33%      61.000us       6.778us           0 b           0 b             9  \n",
      "                   aten::resize_         0.05%       9.900us         0.05%       9.900us       1.100us      31.000us         0.17%      31.000us       3.444us     450.00 Kb     450.00 Kb             9  \n",
      "                   aten::squeeze         0.46%      87.400us         0.50%      94.200us      10.467us     111.000us         0.59%     137.000us      15.222us           0 b           0 b             9  \n",
      "                   aten::reshape         0.58%     109.800us         1.04%     195.200us      15.015us     125.000us         0.67%     249.000us      19.154us           0 b           0 b            13  \n",
      "                      aten::view         0.54%     102.500us         0.54%     102.500us       3.534us     182.000us         0.97%     182.000us       6.276us           0 b           0 b            29  \n",
      "                      aten::stft         0.38%      72.000us         6.37%       1.197ms       1.197ms      49.000us         0.26%       1.189ms       1.189ms     307.20 Kb    -308.00 Kb             1  \n",
      "                     aten::zeros         0.09%      16.100us         0.11%      20.500us      20.500us      13.000us         0.07%      22.000us      22.000us       2.00 Kb           0 b             1  \n",
      "                     aten::zero_         0.01%       1.900us         0.01%       1.900us       1.900us       5.000us         0.03%       5.000us       5.000us           0 b           0 b             1  \n",
      "                    aten::narrow         0.15%      27.800us         0.24%      46.000us      23.000us      39.000us         0.21%      60.000us      30.000us           0 b           0 b             2  \n",
      "                     aten::slice         0.41%      76.800us         0.42%      79.800us      13.300us      76.000us         0.41%      90.000us      15.000us           0 b           0 b             6  \n",
      "                     aten::copy_         1.87%     352.600us         1.87%     352.600us      12.159us     499.000us         2.66%     499.000us      17.207us           0 b           0 b            29  \n",
      "                       aten::mul         4.33%     814.800us         4.33%     814.800us      74.073us     863.000us         4.60%     863.000us      78.455us       4.03 Mb       4.03 Mb            11  \n",
      "                  aten::_fft_r2c         4.99%     939.400us         5.16%     971.100us     971.100us     918.000us         4.89%     973.000us     973.000us     307.20 Kb           0 b             1  \n",
      "                   aten::permute         0.54%     100.800us         0.56%     106.000us      15.143us     105.000us         0.56%     134.000us      19.143us           0 b           0 b             7  \n",
      "                aten::transpose_         0.06%      11.000us         0.06%      11.800us      11.800us      12.000us         0.06%      14.000us      14.000us           0 b           0 b             1  \n",
      "            aten::_reshape_alias         0.05%       8.900us         0.05%       8.900us       8.900us      11.000us         0.06%      11.000us      11.000us           0 b           0 b             1  \n",
      "                       aten::abs         0.82%     155.100us         2.60%     488.400us     244.200us     128.000us         0.68%     494.000us     247.000us     153.60 Kb           0 b             2  \n",
      "                aten::empty_like         0.34%      63.900us         0.42%      78.900us       9.862us      67.000us         0.36%     101.000us      12.625us     586.35 Kb           0 b             8  \n",
      "             aten::empty_strided         0.10%      19.200us         0.10%      19.200us       1.280us      53.000us         0.28%      53.000us       3.533us     153.65 Kb     153.65 Kb            15  \n",
      "                      aten::real         0.09%      16.200us         0.18%      34.600us      34.600us      13.000us         0.07%      35.000us      35.000us           0 b           0 b             1  \n",
      "              aten::view_as_real         0.01%       2.200us         0.01%       2.200us       2.200us       4.000us         0.02%       4.000us       4.000us           0 b           0 b             1  \n",
      "                    aten::select         0.08%      15.300us         0.09%      16.200us      16.200us      16.000us         0.09%      18.000us      18.000us           0 b           0 b             1  \n",
      "                       aten::pow         2.15%     404.000us         2.17%     407.900us      81.580us     412.000us         2.20%     434.000us      86.800us     943.35 Kb     943.35 Kb             5  \n",
      "               aten::result_type         0.01%       2.300us         0.01%       2.300us       0.460us      10.000us         0.05%      10.000us       2.000us           0 b           0 b             5  \n",
      "                 aten::transpose         0.61%     113.800us         0.64%     120.800us      13.422us      75.000us         0.40%     140.000us      15.556us           0 b           0 b             9  \n",
      "                    aten::matmul         0.35%      66.000us         1.46%     273.700us     273.700us      38.000us         0.20%     275.000us     275.000us      47.81 Kb           0 b             1  \n",
      "                    aten::expand         0.45%      85.300us         0.47%      89.300us       9.922us      84.000us         0.45%     115.000us      12.778us           0 b           0 b             9  \n",
      "                       aten::bmm         0.86%     161.700us         0.86%     162.100us     162.100us     165.000us         0.88%     167.000us     167.000us      47.81 Kb      47.81 Kb             1  \n",
      "              aten::resolve_conj         0.01%       2.700us         0.01%       2.700us       0.169us      42.000us         0.22%      42.000us       2.625us           0 b           0 b            16  \n",
      "              aten::_unsafe_view         0.02%       3.800us         0.02%       3.800us       3.800us       5.000us         0.03%       5.000us       5.000us           0 b           0 b             1  \n",
      "                       aten::add         3.88%     729.500us         4.94%     929.000us      46.450us     772.000us         4.11%       1.001ms      50.050us       3.78 Mb       3.78 Mb            20  \n",
      "                  aten::_to_copy         1.47%     277.400us         1.66%     312.700us      22.336us     264.000us         1.41%     384.000us      27.429us          56 b           0 b            14  \n",
      "                       aten::log         0.30%      56.500us         0.30%      56.500us      56.500us      60.000us         0.32%      60.000us      60.000us      47.81 Kb      47.81 Kb             1  \n",
      "                      aten::mean         0.85%     160.500us         3.84%     721.700us      90.212us     236.000us         1.26%     765.000us      95.625us       2.67 Kb       2.65 Kb             8  \n",
      "                       aten::sum         1.42%     268.000us         1.49%     280.800us      28.080us     286.000us         1.52%     335.000us      33.500us       4.50 Kb       4.50 Kb            10  \n",
      "                     aten::fill_         0.06%      11.600us         0.06%      11.600us       1.160us      45.000us         0.24%      45.000us       4.500us           0 b           0 b            10  \n",
      "                      aten::div_         0.95%     178.700us         2.10%     395.900us      49.488us      80.000us         0.43%     344.000us      43.000us          16 b         -16 b             8  \n",
      "                       aten::sub         0.58%     109.900us         0.58%     109.900us      18.317us     108.000us         0.58%     108.000us      18.000us     950.06 Kb     950.06 Kb             6  \n",
      "                aten::contiguous         0.18%      34.700us         1.05%     197.800us      49.450us      32.000us         0.17%     207.000us      51.750us     385.31 Kb           0 b             4  \n",
      "                     aten::clone         0.49%      91.600us         0.87%     163.100us      40.775us      52.000us         0.28%     175.000us      43.750us     385.31 Kb           0 b             4  \n",
      "               aten::thnn_conv2d         0.14%      26.000us         3.22%     606.100us     303.050us      39.000us         0.21%     610.000us     305.000us     450.00 Kb           0 b             2  \n",
      "      aten::_slow_conv2d_forward         2.67%     501.500us         3.08%     580.100us     290.050us     458.000us         2.44%     571.000us     285.500us     450.00 Kb    -187.50 Kb             2  \n",
      "                      aten::sqrt         0.16%      29.600us         0.16%      29.600us       9.867us      38.000us         0.20%      38.000us      12.667us       3.42 Kb       3.42 Kb             3  \n",
      "                       aten::div         0.57%     106.800us         0.57%     106.800us      21.360us     122.000us         0.65%     122.000us      24.400us     459.00 Kb     459.00 Kb             5  \n",
      "                aten::layer_norm         0.17%      32.100us         3.29%     619.500us     206.500us      34.000us         0.18%     628.000us     209.333us     341.02 Kb           0 b             3  \n",
      "         aten::native_layer_norm         2.25%     423.200us         3.12%     587.400us     195.800us     381.000us         2.03%     594.000us     198.000us     341.02 Kb    -337.50 Kb             3  \n",
      "                    aten::linear         1.61%     302.900us         9.26%       1.742ms     248.886us     219.000us         1.17%       1.759ms     251.286us       1.65 Mb           0 b             7  \n",
      "                         aten::t         0.43%      81.000us         0.86%     161.000us      23.000us     100.000us         0.53%     193.000us      27.571us           0 b           0 b             7  \n",
      "                     aten::addmm         4.91%     924.400us         6.18%       1.163ms     166.157us     863.000us         4.60%       1.199ms     171.286us       1.65 Mb       1.65 Mb             7  \n",
      "                      aten::gelu         3.02%     568.900us         3.02%     568.900us     189.633us     584.000us         3.11%     584.000us     194.667us       1.32 Mb       1.32 Mb             3  \n",
      "        aten::linalg_vector_norm         1.68%     315.900us         1.68%     315.900us     105.300us     331.000us         1.76%     331.000us     110.333us       9.00 Kb       9.00 Kb             3  \n",
      "                     aten::empty         0.01%       1.900us         0.01%       1.900us       1.900us       0.000us         0.00%       0.000us       0.000us     112.50 Kb     112.50 Kb             1  \n",
      "                       aten::cat         0.66%     124.200us         0.74%     140.100us      70.050us     118.000us         0.63%     147.000us      73.500us     342.00 Kb     342.00 Kb             2  \n",
      "                aten::batch_norm         0.14%      26.200us         1.73%     325.300us     108.433us      26.000us         0.14%     350.000us     116.667us      47.44 Kb           0 b             3  \n",
      "    aten::_batch_norm_impl_index         0.39%      73.700us         1.59%     299.100us      99.700us      45.000us         0.24%     324.000us     108.000us      47.44 Kb           0 b             3  \n",
      "         aten::native_batch_norm         0.99%     186.400us         1.18%     222.000us      74.000us     200.000us         1.07%     267.000us      89.000us      47.44 Kb     -11.06 Kb             3  \n",
      "                      aten::tanh         0.26%      48.800us         0.26%      48.800us      48.800us      53.000us         0.28%      53.000us      53.000us      42.19 Kb      42.19 Kb             1  \n",
      "                    aten::detach         0.00%       0.800us         0.00%       0.800us       0.800us       3.000us         0.02%       3.000us       3.000us           0 b           0 b             1  \n",
      "                   aten::softmax         0.08%      14.200us         0.35%      65.300us      65.300us      12.000us         0.06%      68.000us      68.000us     337.50 Kb           0 b             1  \n",
      "                  aten::_softmax         0.27%      51.100us         0.27%      51.100us      51.100us      56.000us         0.30%      56.000us      56.000us     337.50 Kb     337.50 Kb             1  \n",
      "                     aten::clamp         0.08%      15.300us         0.08%      15.500us      15.500us      18.000us         0.10%      20.000us      20.000us       2.25 Kb       2.25 Kb             1  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 18.809ms\n",
      "Self CUDA time total: 18.763ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwjln\\AppData\\Local\\Temp\\ipykernel_9852\\145856219.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load(r'C:\\Users\\jwjln\\Desktop\\SV\\SpeakerVerification\\experiments\\NeXt_TDNN_light_C192_B1_K65\\NeXt_TDNN_light_C192_B1_K65.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['feature_extractor.pre_emphasis.flipped_filter', 'feature_extractor.mel_spectrogram.spectrogram.window', 'feature_extractor.mel_spectrogram.mel_scale.fb', 'model.stages.0.0.dwconv.weight', 'model.stages.0.0.dwconv.bias', 'model.stages.0.0.norm.weight', 'model.stages.0.0.norm.bias', 'model.stages.0.0.pwconv1.weight', 'model.stages.0.0.pwconv1.bias', 'model.stages.0.0.grn.gamma', 'model.stages.0.0.grn.beta', 'model.stages.0.0.pwconv2.weight', 'model.stages.0.0.pwconv2.bias', 'model.stages.1.0.dwconv.weight', 'model.stages.1.0.dwconv.bias', 'model.stages.1.0.norm.weight', 'model.stages.1.0.norm.bias', 'model.stages.1.0.pwconv1.weight', 'model.stages.1.0.pwconv1.bias', 'model.stages.1.0.grn.gamma', 'model.stages.1.0.grn.beta', 'model.stages.1.0.pwconv2.weight', 'model.stages.1.0.pwconv2.bias', 'model.stages.2.0.dwconv.weight', 'model.stages.2.0.dwconv.bias', 'model.stages.2.0.norm.weight', 'model.stages.2.0.norm.bias', 'model.stages.2.0.pwconv1.weight', 'model.stages.2.0.pwconv1.bias', 'model.stages.2.0.grn.gamma', 'model.stages.2.0.grn.beta', 'model.stages.2.0.pwconv2.weight', 'model.stages.2.0.pwconv2.bias', 'model.MFA.0.weight', 'model.MFA.0.bias', 'model.MFA.1.weight', 'model.MFA.1.bias', 'aggregate.conv_1.weight', 'aggregate.conv_1.bias', 'aggregate.conv_2.weight', 'aggregate.conv_2.bias', 'aggregate.bn1.weight', 'aggregate.bn1.bias', 'aggregate.bn1.running_mean', 'aggregate.bn1.running_var', 'aggregate.bn2.weight', 'aggregate.bn2.bias', 'aggregate.bn2.running_mean', 'aggregate.bn2.running_var', 'aggregate.fc.weight', 'aggregate.fc.bias', 'aggregate.bn3.weight', 'aggregate.bn3.bias', 'aggregate.bn3.running_mean', 'aggregate.bn3.running_var', 'loss_function.weight'], unexpected_keys=['speaker_net.feature_extractor.pre_emphasis.flipped_filter', 'speaker_net.feature_extractor.mel_spectrogram.spectrogram.window', 'speaker_net.feature_extractor.mel_spectrogram.mel_scale.fb', 'speaker_net.model.stages.0.0.dwconv.weight', 'speaker_net.model.stages.0.0.dwconv.bias', 'speaker_net.model.stages.0.0.norm.weight', 'speaker_net.model.stages.0.0.norm.bias', 'speaker_net.model.stages.0.0.pwconv1.weight', 'speaker_net.model.stages.0.0.pwconv1.bias', 'speaker_net.model.stages.0.0.grn.gamma', 'speaker_net.model.stages.0.0.grn.beta', 'speaker_net.model.stages.0.0.pwconv2.weight', 'speaker_net.model.stages.0.0.pwconv2.bias', 'speaker_net.model.stages.1.0.dwconv.weight', 'speaker_net.model.stages.1.0.dwconv.bias', 'speaker_net.model.stages.1.0.norm.weight', 'speaker_net.model.stages.1.0.norm.bias', 'speaker_net.model.stages.1.0.pwconv1.weight', 'speaker_net.model.stages.1.0.pwconv1.bias', 'speaker_net.model.stages.1.0.grn.gamma', 'speaker_net.model.stages.1.0.grn.beta', 'speaker_net.model.stages.1.0.pwconv2.weight', 'speaker_net.model.stages.1.0.pwconv2.bias', 'speaker_net.model.stages.2.0.dwconv.weight', 'speaker_net.model.stages.2.0.dwconv.bias', 'speaker_net.model.stages.2.0.norm.weight', 'speaker_net.model.stages.2.0.norm.bias', 'speaker_net.model.stages.2.0.pwconv1.weight', 'speaker_net.model.stages.2.0.pwconv1.bias', 'speaker_net.model.stages.2.0.grn.gamma', 'speaker_net.model.stages.2.0.grn.beta', 'speaker_net.model.stages.2.0.pwconv2.weight', 'speaker_net.model.stages.2.0.pwconv2.bias', 'speaker_net.model.MFA.0.weight', 'speaker_net.model.MFA.0.bias', 'speaker_net.model.MFA.1.weight', 'speaker_net.model.MFA.1.bias', 'speaker_net.aggregate.conv_1.weight', 'speaker_net.aggregate.conv_1.bias', 'speaker_net.aggregate.conv_2.weight', 'speaker_net.aggregate.conv_2.bias', 'speaker_net.aggregate.bn1.weight', 'speaker_net.aggregate.bn1.bias', 'speaker_net.aggregate.bn1.running_mean', 'speaker_net.aggregate.bn1.running_var', 'speaker_net.aggregate.bn1.num_batches_tracked', 'speaker_net.aggregate.bn2.weight', 'speaker_net.aggregate.bn2.bias', 'speaker_net.aggregate.bn2.running_mean', 'speaker_net.aggregate.bn2.running_var', 'speaker_net.aggregate.bn2.num_batches_tracked', 'speaker_net.aggregate.fc.weight', 'speaker_net.aggregate.fc.bias', 'speaker_net.aggregate.bn3.weight', 'speaker_net.aggregate.bn3.bias', 'speaker_net.aggregate.bn3.running_mean', 'speaker_net.aggregate.bn3.running_var', 'speaker_net.aggregate.bn3.num_batches_tracked'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "dic = torch.load('./experiments/NeXt_TDNN_light_C192_B1_K65/NeXt_TDNN_light_C192_B1_K65.pt')\n",
    "speaker_net.load_state_dict(dic['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50700/50700 [03:47<00:00, 222.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine EER : 36.34319526627219, Euclidean EER : 36.34319526627219\n",
      "Cosine MinDCF : 0.9282445759368835, Euclidean MinDCF : 0.9282445759368835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwjln\\AppData\\Local\\Temp\\ipykernel_7364\\821997797.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load('./experiments/K_NeXt_TDNN/ckpt_5.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knext\n",
    "dic = torch.load('./experiments/K_NeXt_TDNN/ckpt_5.pt')\n",
    "speaker_net.load_state_dict(dic['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50700/50700 [15:14<00:00, 55.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine EER : 11.44378698224852, Euclidean EER : 11.44378698224852\n",
      "Cosine MinDCF : 0.4206311637080868, Euclidean MinDCF : 0.4206311637080868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001005411148071289\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from eval import *\n",
    "\n",
    "test_audio_file = 'KHOtest.wav' ####\n",
    "\n",
    "speaker_net.eval()\n",
    "test_audio = load_audio(test_audio_file, DEVICE)\n",
    "\n",
    "start = time.time()\n",
    "test_emb = speaker_net(test_audio.unsqueeze(0))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
