{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from SpeakerNet import SpeakerNet\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/K_NeXt_TDNN.yaml') as file:\n",
    "#with open('toy.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "BATCH_SIZE = config['PARAMS']['BATCH_SIZE']\n",
    "BASE_LR = float(config['PARAMS']['BASE_LR'])\n",
    "NUM_WORKER = config['PARAMS']['NUM_WORKER']\n",
    "CHANNEL_SIZE = config['PARAMS']['CHANNEL_SIZE']\n",
    "EMBEDDING_SIZE = config['PARAMS']['EMBEDDING_SIZE']\n",
    "MAX_FRAME = config['PARAMS']['MAX_FRAME']\n",
    "SAMPLING_RATE = config['PARAMS']['SAMPLING_RATE']\n",
    "MAX_EPOCH = config['PARAMS']['MAX_EPOCH']\n",
    "DEVICE = 'cpu' #config['PARAMS']['DEVICE']\n",
    "BASE_PATH = config['PARAMS']['BASE_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised AAMSoftmax margin 0.300 scale 40.000\n",
      "⚡ feature_extractor ⚡\n",
      "Mel_Spectrogram(\n",
      "  (pre_emphasis): PreEmphasis()\n",
      "  (mel_spectrogram): MelSpectrogram(\n",
      "    (spectrogram): Spectrogram()\n",
      "    (mel_scale): MelScale()\n",
      "  )\n",
      ")\n",
      "⚡ spec_aug ⚡\n",
      "SpecAugment(\n",
      "  (fm): FrequencyMasking()\n",
      "  (tm): TimeMasking()\n",
      ")\n",
      "⚡ model ⚡\n",
      "NeXtTDNN(\n",
      "  (stem): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(80, 192, kernel_size=(4,), stride=(1,))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): TSConvNeXt_light(\n",
      "        (dwconv): Conv1d(192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (grn): GRN()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (MFA): Sequential(\n",
      "    (0): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      "    (1): LayerNorm()\n",
      "  )\n",
      ")\n",
      "⚡ aggregation ⚡\n",
      "VAP_BN_FC_BN(\n",
      "  (conv_1): Conv1d(576, 72, kernel_size=(1,), stride=(1,))\n",
      "  (conv_2): Conv1d(72, 576, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (tanh): Tanh()\n",
      "  (bn2): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=1152, out_features=192, bias=True)\n",
      "  (bn3): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "⚡ loss ⚡\n",
      "LossFunction(\n",
      "  (ce): CrossEntropyLoss()\n",
      ")\n",
      "Initialised AdamW optimizer\n",
      "Initialised step LR scheduler\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = importlib.import_module('preprocessing.mel_transform').__getattribute__(\"feature_extractor\")\n",
    "feature_extractor = feature_extractor(*config['FEATURE_EXTRACTOR'].values()).to(DEVICE)\n",
    "\n",
    "#fe = feature_extractor(x.to(DEVICE))\n",
    "#print('feature extractor :', fe.shape)\n",
    "\n",
    "spec_aug = importlib.import_module('preprocessing.spec_aug').__getattribute__(\"spec_aug\")\n",
    "spec_aug = spec_aug(*config['SPEC_AUG'].values()).to(DEVICE)\n",
    "\n",
    "#sa = spec_aug(fe)\n",
    "#print('spec aug :', sa.shape)\n",
    "\n",
    "model_cfg = config['MODEL']\n",
    "model = importlib.import_module('models.NeXt_TDNN').__getattribute__(\"MainModel\")\n",
    "model =  model(\n",
    "    depths = model_cfg['depths'], \n",
    "    dims = model_cfg['dims'],\n",
    "    kernel_size = model_cfg['kernel_size'],\n",
    "    block = model_cfg['block']\n",
    ").to(DEVICE)\n",
    "\n",
    "#m = model(sa.to(DEVICE))\n",
    "#print('model :', m.shape)\n",
    "\n",
    "aggregation = importlib.import_module('aggregation.vap_bn_tanh_fc_bn').__getattribute__(\"Aggregation\")\n",
    "aggregation = aggregation(*config['AGGREGATION'].values()).to(DEVICE)\n",
    "\n",
    "#a = aggregation(m).to(DEVICE)\n",
    "#print('aggregation : ', a.shape)\n",
    "\n",
    "loss_function = importlib.import_module(\"loss.aamsoftmax\").__getattribute__(\"LossFunction\")\n",
    "loss_function = loss_function(*config['LOSS'].values())\n",
    "\n",
    "speaker_net = SpeakerNet(feature_extractor = feature_extractor,\n",
    "                       spec_aug = spec_aug, \n",
    "                       model = model,\n",
    "                       aggregation=aggregation,\n",
    "                       loss_function = loss_function).to(DEVICE)\n",
    "\n",
    "optimizer = importlib.import_module(\"optimizer.\" + 'adamw').__getattribute__(\"Optimizer\")\n",
    "optimizer = optimizer(speaker_net.parameters(), lr= BASE_LR*BATCH_SIZE, weight_decay = 0.01,)    \n",
    "\n",
    "scheduler = importlib.import_module(\"scheduler.\" + 'steplr').__getattribute__(\"Scheduler\")\n",
    "scheduler = scheduler(optimizer, step_size = 10, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerNet(\n",
      "  1.63 M, 84.888% Params, 420.52 MMac, 98.346% MACs, \n",
      "  (feature_extractor): Mel_Spectrogram(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (pre_emphasis): PreEmphasis(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (mel_spectrogram): MelSpectrogram(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (spectrogram): Spectrogram(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (mel_scale): MelScale(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (spec_aug): SpecAugment(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (fm): FrequencyMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (tm): TimeMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (model): NeXtTDNN(\n",
      "    1.32 M, 68.832% Params, 395.25 MMac, 92.439% MACs, \n",
      "    (stem): ModuleList(\n",
      "      (0): Sequential(\n",
      "        61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, \n",
      "        (0): Conv1d(61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, 80, 192, kernel_size=(4,), stride=(1,))\n",
      "        (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (stages): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "        (0): TSConvNeXt_light(\n",
      "          308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "          (dwconv): Conv1d(12.67 k, 0.661% Params, 3.79 MMac, 0.886% MACs, 192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "          (norm): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv1): Linear(148.22 k, 7.732% Params, 44.32 MMac, 10.365% MACs, in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(0, 0.000% Params, 229.63 KMac, 0.054% MACs, approximate='none')\n",
      "          (grn): GRN(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv2): Linear(147.65 k, 7.701% Params, 44.15 MMac, 10.325% MACs, in_features=768, out_features=192, bias=True)\n",
      "          (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (MFA): Sequential(\n",
      "      332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, \n",
      "      (0): Conv1d(332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, 576, 576, kernel_size=(1,), stride=(1,))\n",
      "      (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (aggregate): VAP_BN_FC_BN(\n",
      "    307.8 k, 16.055% Params, 25.26 MMac, 5.908% MACs, \n",
      "    (conv_1): Conv1d(41.54 k, 2.167% Params, 12.42 MMac, 2.905% MACs, 576, 72, kernel_size=(1,), stride=(1,))\n",
      "    (conv_2): Conv1d(42.05 k, 2.193% Params, 12.57 MMac, 2.940% MACs, 72, 576, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(144, 0.008% Params, 43.06 KMac, 0.010% MACs, 72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (tanh): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (bn2): BatchNorm1d(2.3 k, 0.120% Params, 2.3 KMac, 0.001% MACs, 1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): Linear(221.38 k, 11.547% Params, 221.38 KMac, 0.052% MACs, in_features=1152, out_features=192, bias=True)\n",
      "    (bn3): BatchNorm1d(384, 0.020% Params, 384.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (loss_function): LossFunction(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (ce): CrossEntropyLoss(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "ptflops: MMac: 427.59, Params: 1.92\n",
      "thop: MMac: 418.415136, Params: 1.627416\n",
      "torchinfo: MMac: 155.27652, Params: 1.917144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('427.59', '1.92', 418.415136, 1.627416, 155.27652, 1.917144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_param_mmac(speaker_net, int(160*300 + 240), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> GPU:0 총 VRAM: 8188.00 MB\n",
      ">> GPU:0 사용 중인 VRAM: 805.69 MB\n",
      ">> GPU:0 남은 VRAM: 7382.31 MB\n"
     ]
    }
   ],
   "source": [
    "from check_vram import check_vram\n",
    "\n",
    "check_vram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_net.eval()\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_stack=True,profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        speaker_net(torch.randn(24320,).unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls                                                                      Input Shapes  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "                 model_inference        12.25%      14.417ms       100.00%     117.645ms     117.645ms       9.448ms         7.34%     128.715ms     128.715ms           0 b     -15.94 Mb             1                                                                                []  \n",
      "                      aten::stft         0.44%     519.300us        21.63%      25.449ms      25.449ms      15.000us         0.01%      25.244ms      25.244ms     307.20 Kb    -308.00 Kb             1                                       [[1, 24832], [], [], [], [400], [], [], []]  \n",
      "                  aten::_fft_r2c        20.45%      24.053ms        20.49%      24.110ms      24.110ms      23.981ms        18.63%      23.998ms      23.998ms     307.20 Kb           0 b             1                                                       [[1, 153, 512], [], [], []]  \n",
      "                    aten::conv1d         0.04%      41.300us        15.94%      18.751ms      18.751ms       5.000us         0.00%      19.010ms      19.010ms      95.00 Kb           0 b             1                                    [[1, 1, 24321], [1, 1, 2], [], [], [], [], []]  \n",
      "               aten::convolution         0.04%      48.600us        15.90%      18.710ms      18.710ms       3.000us         0.00%      19.005ms      19.005ms      95.00 Kb           0 b             1                            [[1, 1, 24321], [1, 1, 2], [], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.24%     284.500us        15.86%      18.661ms      18.661ms       1.217ms         0.95%      19.002ms      19.002ms      95.00 Kb           0 b             1            [[1, 1, 24321], [1, 1, 2], [], [], [], [], [], [], [], [], [], [], []]  \n",
      "        aten::mkldnn_convolution        15.54%      18.280ms        15.57%      18.318ms      18.318ms      17.762ms        13.80%      17.771ms      17.771ms      95.00 Kb           0 b             1                              [[1, 1, 1, 24321], [1, 1, 1, 2], [], [], [], [], []]  \n",
      "                    aten::conv1d         0.06%      69.700us        13.33%      15.685ms       5.228ms     628.000us         0.49%      14.948ms       4.983ms     337.50 Kb           0 b             3                              [[1, 192, 150], [192, 1, 65], [192], [], [], [], []]  \n",
      "               aten::convolution         0.09%     102.000us        13.27%      15.615ms       5.205ms      12.000us         0.01%      14.320ms       4.773ms     337.50 Kb           0 b             3                      [[1, 192, 150], [192, 1, 65], [192], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.18%     214.200us        13.19%      15.513ms       5.171ms       1.245ms         0.97%      14.308ms       4.769ms     337.50 Kb           0 b             3      [[1, 192, 150], [192, 1, 65], [192], [], [], [], [], [], [], [], [], [], []]  \n",
      "        aten::mkldnn_convolution        12.82%      15.079ms        12.88%      15.155ms       5.052ms      11.179ms         8.69%      11.816ms       3.939ms     337.50 Kb           0 b             3                        [[1, 192, 1, 150], [192, 1, 1, 65], [192], [], [], [], []]  \n",
      "                    aten::matmul         0.73%     860.100us         5.59%       6.578ms       6.578ms       1.213ms         0.94%       6.816ms       6.816ms      47.81 Kb           0 b             1                                                        [[1, 153, 257], [257, 80]]  \n",
      "                       aten::bmm         4.78%       5.626ms         4.78%       5.627ms       5.627ms       5.578ms         4.33%       5.581ms       5.581ms      47.81 Kb      47.81 Kb             1                                                     [[1, 153, 257], [1, 257, 80]]  \n",
      "                        aten::to         0.24%     279.900us         0.81%     957.500us      68.393us     632.000us         0.49%       4.478ms     319.857us          56 b           0 b            14                                                              [[], [], [], [], []]  \n",
      "                    aten::linear         0.19%     227.900us         1.55%       1.822ms     607.467us       1.217ms         0.95%       4.343ms       1.448ms       1.32 Mb           0 b             3                                                [[1, 150, 192], [768, 192], [768]]  \n",
      "                      aten::gelu         3.56%       4.188ms         3.56%       4.188ms       1.396ms       4.121ms         3.20%       4.121ms       1.374ms       1.32 Mb       1.32 Mb             3                                                               [[1, 150, 768], []]  \n",
      "                  aten::_to_copy         0.47%     558.500us         0.58%     677.600us      48.400us       3.192ms         2.48%       3.846ms     274.714us          56 b           0 b            14                                                      [[], [], [], [], [], [], []]  \n",
      "                     aten::empty         0.33%     384.200us         0.33%     384.200us       7.684us       3.840ms         2.98%       3.840ms      76.800us       2.14 Mb       2.14 Mb            50                                                          [[], [], [], [], [], []]  \n",
      "                    aten::linear         0.27%     317.800us         1.07%       1.256ms     418.633us     626.000us         0.49%       3.762ms       1.254ms     337.50 Kb           0 b             3                                                [[1, 150, 768], [192, 768], [192]]  \n",
      "                aten::layer_norm         0.17%     198.300us         1.42%       1.668ms     556.000us     597.000us         0.46%       3.724ms       1.241ms     341.02 Kb           0 b             3                                         [[1, 150, 192], [], [192], [192], [], []]  \n",
      "         aten::native_layer_norm         0.96%       1.126ms         1.25%       1.470ms     489.900us       1.246ms         0.97%       3.127ms       1.042ms     341.02 Kb    -337.50 Kb             3                                             [[1, 150, 192], [], [192], [192], []]  \n",
      "                    aten::conv1d         0.01%      15.400us         2.25%       2.642ms       2.642ms       3.000us         0.00%       2.490ms       2.490ms     112.50 Kb           0 b             1                               [[1, 80, 153], [192, 80, 4], [192], [], [], [], []]  \n",
      "               aten::convolution         0.06%      71.900us         2.23%       2.627ms       2.627ms       4.000us         0.00%       2.487ms       2.487ms     112.50 Kb           0 b             1                       [[1, 80, 153], [192, 80, 4], [192], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.25%     292.100us         2.17%       2.555ms       2.555ms      12.000us         0.01%       2.483ms       2.483ms     112.50 Kb     -47.81 Kb             1       [[1, 80, 153], [192, 80, 4], [192], [], [], [], [], [], [], [], [], [], []]  \n",
      "                       aten::abs         0.17%     194.200us         1.49%       1.756ms       1.756ms     607.000us         0.47%       2.257ms       2.257ms     153.60 Kb           0 b             1                                                                   [[1, 257, 153]]  \n",
      "                       aten::add         0.08%      97.900us         0.42%     491.200us     163.733us     610.000us         0.47%       1.957ms     652.333us          12 b           0 b             3                                                               [[1, 1, 1], [], []]  \n",
      "                    aten::conv1d         0.02%      21.600us         1.26%       1.485ms       1.485ms       4.000us         0.00%       1.902ms       1.902ms     337.50 Kb           0 b             1                               [[1, 72, 150], [576, 72, 1], [576], [], [], [], []]  \n",
      "               aten::convolution         0.02%      26.600us         1.24%       1.464ms       1.464ms       3.000us         0.00%       1.898ms       1.898ms     337.50 Kb           0 b             1                       [[1, 72, 150], [576, 72, 1], [576], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.06%      73.400us         1.22%       1.437ms       1.437ms       1.247ms         0.97%       1.895ms       1.895ms     337.50 Kb           0 b             1       [[1, 72, 150], [576, 72, 1], [576], [], [], [], [], [], [], [], [], [], []]  \n",
      "                      aten::mean         0.12%     146.100us         0.51%     598.700us     199.567us      22.000us         0.02%       1.893ms     631.000us          12 b          12 b             3                                                         [[1, 1, 768], [], [], []]  \n",
      "                    aten::conv1d         0.01%      13.700us         1.64%       1.929ms       1.929ms     618.000us         0.48%       1.886ms       1.886ms     337.50 Kb           0 b             1                             [[1, 576, 150], [576, 576, 1], [576], [], [], [], []]  \n",
      "                     aten::addmm         0.51%     603.700us         0.63%     744.300us     248.100us      29.000us         0.02%       1.885ms     628.333us     337.50 Kb     337.50 Kb             3                                           [[192], [150, 768], [768, 192], [], []]  \n",
      "                    aten::conv1d         0.01%      16.100us         0.77%     907.100us     907.100us     611.000us         0.47%       1.881ms       1.881ms      42.19 Kb           0 b             1                               [[1, 576, 150], [72, 576, 1], [72], [], [], [], []]  \n",
      "                     aten::addmm         1.07%       1.254ms         1.21%       1.423ms     474.333us      24.000us         0.02%       1.875ms     625.000us       1.32 Mb       1.32 Mb             3                                           [[768], [150, 192], [192, 768], [], []]  \n",
      "                      aten::mean         0.06%      72.100us         0.25%     289.800us     144.900us       1.228ms         0.95%       1.869ms     934.500us       1.17 Kb       1.16 Kb             2                                                       [[1, 192, 150], [], [], []]  \n",
      "                      aten::div_         0.13%     151.500us         0.31%     368.400us     122.800us     602.000us         0.47%       1.857ms     619.000us           0 b         -12 b             3                                                                   [[1, 1, 1], []]  \n",
      "                    aten::expand         0.03%      40.300us         0.04%      43.400us      14.467us       1.206ms         0.94%       1.837ms     612.333us           0 b           0 b             3                                                                   [[768], [], []]  \n",
      "                       aten::abs         1.02%       1.199ms         1.28%       1.511ms       1.511ms       1.024ms         0.80%       1.644ms       1.644ms           0 b           0 b             1                                                    [[1, 257, 153], [1, 257, 153]]  \n",
      "                       aten::pad         0.10%     112.800us         1.52%       1.785ms     892.450us       8.000us         0.01%       1.436ms     718.000us     192.00 Kb           0 b             2                                                       [[1, 1, 24320], [], [], []]  \n",
      "          aten::reflection_pad1d         1.42%       1.672ms         1.42%       1.672ms     836.050us       1.428ms         1.11%       1.428ms     714.000us     192.00 Kb     192.00 Kb             2                                                               [[1, 1, 24320], []]  \n",
      "                       aten::sum         0.13%     152.400us         0.14%     165.100us      82.550us       1.332ms         1.03%       1.340ms     670.000us       4.50 Kb       4.50 Kb             2                                                       [[1, 576, 150], [], [], []]  \n",
      "                aten::batch_norm         0.01%      16.000us         0.33%     390.400us     390.400us       3.000us         0.00%       1.331ms       1.331ms       4.50 Kb           0 b             1                       [[1, 1152], [1152], [1152], [1152], [1152], [], [], [], []]  \n",
      "    aten::_batch_norm_impl_index         0.02%      24.000us         0.32%     374.400us     374.400us       7.000us         0.01%       1.328ms       1.328ms       4.50 Kb           0 b             1                       [[1, 1152], [1152], [1152], [1152], [1152], [], [], [], []]  \n",
      "               aten::convolution         0.02%      22.200us         0.76%     891.000us     891.000us       5.000us         0.00%       1.270ms       1.270ms      42.19 Kb           0 b             1                       [[1, 576, 150], [72, 576, 1], [72], [], [], [], [], [], []]  \n",
      "               aten::convolution         0.02%      21.400us         1.63%       1.916ms       1.916ms       6.000us         0.00%       1.268ms       1.268ms     337.50 Kb           0 b             1                     [[1, 576, 150], [576, 576, 1], [576], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.03%      40.100us         0.74%     868.800us     868.800us     620.000us         0.48%       1.265ms       1.265ms      42.19 Kb           0 b             1       [[1, 576, 150], [72, 576, 1], [72], [], [], [], [], [], [], [], [], [], []]  \n",
      "              aten::_convolution         0.04%      46.100us         1.61%       1.894ms       1.894ms     613.000us         0.48%       1.262ms       1.262ms     337.50 Kb           0 b             1     [[1, 576, 150], [576, 576, 1], [576], [], [], [], [], [], [], [], [], [], []]  \n",
      "                      aten::div_         0.09%     111.200us         0.24%     281.800us      70.450us     620.000us         0.48%       1.261ms     315.250us          16 b           0 b             4                                                                 [[1, 1, 150], []]  \n",
      "                      aten::mean         0.05%      54.300us         0.25%     298.400us     149.200us      16.000us         0.01%       1.256ms     628.000us       1.17 Kb       1.16 Kb             2                                                       [[1, 576, 150], [], [], []]  \n",
      "                   aten::squeeze         0.06%      68.700us         0.06%      75.500us      18.875us     624.000us         0.48%       1.233ms     308.250us           0 b           0 b             4                                                            [[1, 192, 1, 150], []]  \n",
      "                         aten::t         0.05%      61.600us         0.10%     113.200us      37.733us      11.000us         0.01%       1.232ms     410.667us           0 b           0 b             3                                                                      [[192, 768]]  \n",
      "                      aten::mean         0.20%     233.200us         0.66%     776.500us     776.500us       1.210ms         0.94%       1.230ms       1.230ms         320 b         320 b             1                                                        [[1, 80, 153], [], [], []]  \n",
      "               aten::thnn_conv2d         0.49%     573.400us         1.80%       2.112ms       2.112ms     605.000us         0.47%       1.226ms       1.226ms     112.50 Kb           0 b             1                             [[1, 80, 1, 153], [192, 80, 1, 4], [], [192], [], []]  \n",
      "                   aten::reshape         0.03%      31.500us         0.04%      48.700us      16.233us     607.000us         0.47%       1.223ms     407.667us           0 b           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                 aten::transpose         0.04%      45.800us         0.04%      51.600us      17.200us       1.216ms         0.94%       1.221ms     407.000us           0 b           0 b             3                                                              [[192, 768], [], []]  \n",
      "                    aten::linear         0.04%      50.100us         1.17%       1.382ms       1.382ms       1.190ms         0.92%       1.215ms       1.215ms         768 b           0 b             1                                                   [[1, 1152], [192, 1152], [192]]  \n",
      "                       aten::log         0.85%       1.002ms         0.85%       1.002ms       1.002ms     766.000us         0.60%     766.000us     766.000us      47.81 Kb      47.81 Kb             1                                                                    [[1, 80, 153]]  \n",
      "        aten::linalg_vector_norm         0.88%       1.036ms         0.88%       1.036ms     345.233us     700.000us         0.54%     700.000us     233.333us       9.00 Kb       9.00 Kb             3                                                   [[1, 150, 768], [], [], [], []]  \n",
      "                aten::contiguous         0.04%      44.200us         0.26%     304.100us     101.367us     621.000us         0.48%     654.000us     218.000us     337.50 Kb           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                       aten::pow         0.43%     511.100us         0.44%     514.700us     257.350us     631.000us         0.49%     638.000us     319.000us     675.00 Kb     675.00 Kb             2                                                               [[1, 576, 150], []]  \n",
      "                aten::batch_norm         0.15%     170.700us         1.36%       1.604ms       1.604ms       4.000us         0.00%     636.000us     636.000us      42.19 Kb           0 b             1                            [[1, 72, 150], [72], [72], [72], [72], [], [], [], []]  \n",
      "        aten::mkldnn_convolution         1.53%       1.805ms         1.54%       1.815ms       1.815ms       9.000us         0.01%     634.000us     634.000us     337.50 Kb           0 b             1                       [[1, 576, 1, 150], [576, 576, 1, 1], [576], [], [], [], []]  \n",
      "        aten::mkldnn_convolution         0.66%     781.700us         0.68%     796.300us     796.300us       9.000us         0.01%     632.000us     632.000us      42.19 Kb           0 b             1                         [[1, 576, 1, 150], [72, 576, 1, 1], [72], [], [], [], []]  \n",
      "    aten::_batch_norm_impl_index         0.03%      32.800us         1.22%       1.433ms       1.433ms       3.000us         0.00%     632.000us     632.000us      42.19 Kb           0 b             1                            [[1, 72, 150], [72], [72], [72], [72], [], [], [], []]  \n",
      "               aten::thnn_conv2d         0.03%      35.100us         1.11%       1.301ms       1.301ms       4.000us         0.00%     632.000us     632.000us     337.50 Kb           0 b             1                             [[1, 72, 1, 150], [576, 72, 1, 1], [], [576], [], []]  \n",
      "             aten::empty_strided         0.07%      84.500us         0.07%      84.500us       5.633us     631.000us         0.49%     631.000us      42.067us     153.65 Kb     153.65 Kb            15                                                          [[], [], [], [], [], []]  \n",
      "                aten::as_strided         0.00%       3.100us         0.00%       3.100us       1.033us     631.000us         0.49%     631.000us     210.333us           0 b           0 b             3                                                               [[768], [], [], []]  \n",
      "                aten::batch_norm         0.01%      12.700us         0.17%     200.800us     200.800us       3.000us         0.00%     631.000us     631.000us         768 b           0 b             1                            [[1, 192], [192], [192], [192], [192], [], [], [], []]  \n",
      "      aten::_slow_conv2d_forward         1.00%       1.176ms         1.08%       1.266ms       1.266ms     614.000us         0.48%     628.000us     628.000us     337.50 Kb           0 b             1                             [[1, 72, 1, 150], [576, 72, 1, 1], [], [576], [], []]  \n",
      "    aten::_batch_norm_impl_index         0.03%      30.000us         0.16%     188.100us     188.100us       4.000us         0.00%     628.000us     628.000us         768 b           0 b             1                            [[1, 192], [192], [192], [192], [192], [], [], [], []]  \n",
      "         aten::native_batch_norm         1.18%       1.385ms         1.19%       1.398ms       1.398ms     614.000us         0.48%     627.000us     627.000us      42.19 Kb        -576 b             1                                [[1, 72, 150], [72], [72], [72], [72], [], [], []]  \n",
      "                       aten::add         0.39%     455.900us         0.39%     455.900us     151.967us     625.000us         0.49%     625.000us     208.333us       1.32 Mb       1.32 Mb             3                                                  [[1, 150, 768], [1, 1, 768], []]  \n",
      "                   aten::permute         0.06%      67.100us         0.06%      72.100us      24.033us     622.000us         0.48%     625.000us     208.333us           0 b           0 b             3                                                               [[1, 150, 192], []]  \n",
      "                aten::as_strided         0.01%       6.000us         0.01%       6.000us       0.750us     623.000us         0.48%     623.000us      77.875us           0 b           0 b             8                                                               [[192], [], [], []]  \n",
      "                      aten::tanh         0.64%     747.900us         0.64%     747.900us     747.900us     623.000us         0.48%     623.000us     623.000us      42.19 Kb      42.19 Kb             1                                                                    [[1, 72, 150]]  \n",
      "                     aten::copy_         0.07%      87.700us         0.07%      87.700us      29.233us     622.000us         0.48%     622.000us     207.333us           0 b           0 b             3                                                      [[150, 192], [150, 192], []]  \n",
      "         aten::native_batch_norm         0.09%     109.800us         0.13%     155.700us     155.700us     613.000us         0.48%     622.000us     622.000us         768 b      -1.50 Kb             1                                [[1, 192], [192], [192], [192], [192], [], [], []]  \n",
      "      aten::_slow_conv2d_forward         1.08%       1.276ms         1.31%       1.539ms       1.539ms      12.000us         0.01%     621.000us     621.000us     112.50 Kb    -187.50 Kb             1                             [[1, 80, 1, 153], [192, 80, 1, 4], [], [192], [], []]  \n",
      "                       aten::mul         0.14%     161.300us         0.14%     161.300us     161.300us     621.000us         0.48%     621.000us     621.000us     337.50 Kb     337.50 Kb             1                                                         [[576, 1], [1, 576, 150]]  \n",
      "                       aten::add         0.05%      62.100us         0.11%     132.800us     132.800us       4.000us         0.00%     620.000us     620.000us      47.81 Kb      47.81 Kb             1                                                            [[1, 80, 153], [], []]  \n",
      "                aten::contiguous         0.05%      54.500us         0.09%     110.900us     110.900us       3.000us         0.00%     619.000us     619.000us      47.81 Kb           0 b             1                                                                [[1, 80, 153], []]  \n",
      "                 aten::unsqueeze         0.03%      35.900us         0.03%      37.100us      18.550us       6.000us         0.00%     619.000us     309.500us           0 b           0 b             2                                                                       [[192], []]  \n",
      "                 aten::unsqueeze         0.03%      37.800us         0.03%      40.600us      13.533us     616.000us         0.48%     619.000us     206.333us           0 b           0 b             3                                                                [[192, 1, 65], []]  \n",
      "                      aten::sqrt         0.60%     708.500us         0.60%     708.500us     354.250us     618.000us         0.48%     618.000us     309.000us       1.17 Kb       1.17 Kb             2                                                                     [[1, 1, 150]]  \n",
      "                       aten::sub         0.08%      90.200us         0.08%      90.200us      45.100us     618.000us         0.48%     618.000us     309.000us     675.00 Kb     675.00 Kb             2                                                  [[1, 576, 150], [1, 1, 150], []]  \n",
      "         aten::native_batch_norm         0.28%     325.200us         0.30%     348.800us     348.800us     604.000us         0.47%     618.000us     618.000us       4.50 Kb      -9.00 Kb             1                           [[1, 1152], [1152], [1152], [1152], [1152], [], [], []]  \n",
      "                     aten::randn         0.59%     694.100us         0.91%       1.068ms       1.068ms     614.000us         0.48%     617.000us     617.000us      95.00 Kb           0 b             1                                                              [[], [], [], [], []]  \n",
      "                       aten::add         0.03%      33.300us         0.08%      96.400us      48.200us       8.000us         0.01%     617.000us     308.500us       1.17 Kb       1.16 Kb             2                                                             [[1, 1, 150], [], []]  \n",
      "                     aten::clone         0.02%      29.200us         0.05%      56.400us      56.400us       7.000us         0.01%     616.000us     616.000us      47.81 Kb           0 b             1                                                                [[1, 80, 153], []]  \n",
      "                      aten::view         0.01%      17.200us         0.01%      17.200us       5.733us     616.000us         0.48%     616.000us     205.333us           0 b           0 b             3                                                               [[1, 150, 192], []]  \n",
      "              aten::resolve_conj         0.00%       1.800us         0.00%       1.800us       0.300us     615.000us         0.48%     615.000us     102.500us           0 b           0 b             6                                                                      [[150, 768]]  \n",
      "                    aten::narrow         0.16%     186.000us         0.19%     220.400us     220.400us     609.000us         0.47%     614.000us     614.000us           0 b           0 b             1                                                               [[512], [], [], []]  \n",
      "              aten::resolve_conj         0.00%       1.700us         0.00%       1.700us       0.283us     614.000us         0.48%     614.000us     102.333us           0 b           0 b             6                                                                      [[150, 192]]  \n",
      "                       aten::add         0.33%     391.700us         0.33%     391.700us      65.283us     612.000us         0.48%     612.000us     102.000us     675.00 Kb     675.00 Kb             6                                                [[1, 192, 150], [1, 192, 150], []]  \n",
      "                       aten::sum         0.04%      51.900us         0.05%      56.600us      28.300us     609.000us         0.47%     611.000us     305.500us           0 b           0 b             2                                          [[1, 192, 150], [], [], [], [1, 1, 150]]  \n",
      "                aten::as_strided         0.01%       6.800us         0.01%       6.800us       1.700us     609.000us         0.47%     609.000us     152.250us           0 b           0 b             4                                                    [[1, 192, 1, 150], [], [], []]  \n",
      "                       aten::sub         0.01%      14.500us         0.01%      14.500us      14.500us     608.000us         0.47%     608.000us     608.000us       2.25 Kb       2.25 Kb             1                                                          [[1, 576], [1, 576], []]  \n",
      "                 aten::transpose         0.02%      17.900us         0.02%      19.500us      19.500us     605.000us         0.47%     607.000us     607.000us           0 b           0 b             1                                                           [[1, 257, 153], [], []]  \n",
      "                       aten::mul         0.41%     478.400us         0.41%     478.400us     159.467us     606.000us         0.47%     606.000us     202.000us       1.32 Mb       1.32 Mb             3                                                      [[1, 150, 768], [1, 1, 768]]  \n",
      "                     aten::copy_         0.20%     236.300us         0.20%     236.300us     236.300us     604.000us         0.47%     604.000us     604.000us           0 b           0 b             1                                                [[1, 257, 153], [1, 257, 153], []]  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
      "Self CPU time total: 117.645ms\n",
      "Self CUDA time total: 128.715ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference        12.25%      14.417ms       100.00%     117.645ms     117.645ms       9.448ms         7.34%     128.715ms     128.715ms           0 b     -15.94 Mb             1  \n",
      "                     aten::randn         0.59%     694.100us         0.91%       1.068ms       1.068ms     614.000us         0.48%     617.000us     617.000us      95.00 Kb           0 b             1  \n",
      "                     aten::empty         0.33%     384.200us         0.33%     384.200us       7.684us       3.840ms         2.98%       3.840ms      76.800us       2.14 Mb       2.14 Mb            50  \n",
      "                   aten::normal_         0.14%     164.300us         0.14%     164.300us     164.300us       2.000us         0.00%       2.000us       2.000us           0 b           0 b             1  \n",
      "                 aten::unsqueeze         0.45%     524.800us         0.48%     566.200us      25.736us     675.000us         0.52%       1.316ms      59.818us           0 b           0 b            22  \n",
      "                aten::as_strided         0.11%     131.300us         0.11%     131.300us       1.989us       1.939ms         1.51%       1.939ms      29.379us           0 b           0 b            66  \n",
      "                        aten::to         0.24%     287.300us         0.82%     964.900us      45.948us     642.000us         0.50%       4.488ms     213.714us          56 b           0 b            21  \n",
      "                       aten::pad         0.10%     112.800us         1.52%       1.785ms     892.450us       8.000us         0.01%       1.436ms     718.000us     192.00 Kb           0 b             2  \n",
      "          aten::reflection_pad1d         1.42%       1.672ms         1.42%       1.672ms     836.050us       1.428ms         1.11%       1.428ms     714.000us     192.00 Kb     192.00 Kb             2  \n",
      "                    aten::conv1d         0.15%     177.800us        35.19%      41.400ms       5.175ms       1.869ms         1.45%      42.117ms       5.265ms       1.23 Mb           0 b             8  \n",
      "               aten::convolution         0.25%     292.700us        35.04%      41.222ms       5.153ms      33.000us         0.03%      40.248ms       5.031ms       1.23 Mb           0 b             8  \n",
      "              aten::_convolution         0.81%     950.400us        34.79%      40.930ms       5.116ms       4.954ms         3.85%      40.215ms       5.027ms       1.23 Mb     -47.81 Kb             8  \n",
      "        aten::mkldnn_convolution        30.55%      35.946ms        30.67%      36.084ms       6.014ms      28.959ms        22.50%      30.853ms       5.142ms     812.19 Kb           0 b             6  \n",
      "               aten::as_strided_         0.06%      72.100us         0.06%      72.100us       8.011us      17.000us         0.01%      17.000us       1.889us           0 b           0 b             9  \n",
      "                   aten::resize_         0.04%      42.100us         0.04%      42.100us       4.678us      16.000us         0.01%      16.000us       1.778us     450.00 Kb     450.00 Kb             9  \n",
      "                   aten::squeeze         0.13%     158.000us         0.15%     171.300us      19.033us     643.000us         0.50%       1.258ms     139.778us           0 b           0 b             9  \n",
      "                   aten::reshape         0.36%     421.300us         0.46%     546.500us      42.038us       1.829ms         1.42%       2.462ms     189.385us           0 b           0 b            13  \n",
      "                      aten::view         0.14%     169.600us         0.14%     169.600us       5.848us     660.000us         0.51%     660.000us      22.759us           0 b           0 b            29  \n",
      "                      aten::stft         0.44%     519.300us        21.63%      25.449ms      25.449ms      15.000us         0.01%      25.244ms      25.244ms     307.20 Kb    -308.00 Kb             1  \n",
      "                     aten::zeros         0.29%     344.400us         0.30%     356.300us     356.300us       4.000us         0.00%       7.000us       7.000us       2.00 Kb           0 b             1  \n",
      "                     aten::zero_         0.01%       7.300us         0.01%       7.300us       7.300us       1.000us         0.00%       1.000us       1.000us           0 b           0 b             1  \n",
      "                    aten::narrow         0.18%     207.700us         0.22%     258.100us     129.050us     613.000us         0.48%     622.000us     311.000us           0 b           0 b             2  \n",
      "                     aten::slice         0.17%     194.300us         0.17%     203.200us      33.867us      17.000us         0.01%      28.000us       4.667us           0 b           0 b             6  \n",
      "                     aten::copy_         0.75%     882.700us         0.75%     882.700us      30.438us       1.871ms         1.45%       1.871ms      64.517us           0 b           0 b            29  \n",
      "                       aten::mul         1.24%       1.459ms         1.24%       1.459ms     132.600us       2.436ms         1.89%       2.436ms     221.455us       4.03 Mb       4.03 Mb            11  \n",
      "                  aten::_fft_r2c        20.45%      24.053ms        20.49%      24.110ms      24.110ms      23.981ms        18.63%      23.998ms      23.998ms     307.20 Kb           0 b             1  \n",
      "                   aten::permute         0.14%     166.500us         0.15%     177.800us      25.400us     633.000us         0.49%     642.000us      91.714us           0 b           0 b             7  \n",
      "                aten::transpose_         0.03%      39.800us         0.04%      43.200us      43.200us       4.000us         0.00%       5.000us       5.000us           0 b           0 b             1  \n",
      "            aten::_reshape_alias         0.03%      35.200us         0.03%      35.200us      35.200us       2.000us         0.00%       2.000us       2.000us           0 b           0 b             1  \n",
      "                       aten::abs         1.18%       1.393ms         2.78%       3.267ms       1.633ms       1.631ms         1.27%       3.901ms       1.950ms     153.60 Kb           0 b             2  \n",
      "                aten::empty_like         0.12%     136.200us         0.16%     184.400us      23.050us      26.000us         0.02%      37.000us       4.625us     586.35 Kb           0 b             8  \n",
      "             aten::empty_strided         0.07%      84.500us         0.07%      84.500us       5.633us     631.000us         0.49%     631.000us      42.067us     153.65 Kb     153.65 Kb            15  \n",
      "                      aten::real         0.03%      36.900us         0.06%      68.000us      68.000us       6.000us         0.00%      12.000us      12.000us           0 b           0 b             1  \n",
      "              aten::view_as_real         0.00%       5.500us         0.00%       5.500us       5.500us       1.000us         0.00%       1.000us       1.000us           0 b           0 b             1  \n",
      "                    aten::select         0.02%      21.800us         0.02%      25.600us      25.600us       3.000us         0.00%       5.000us       5.000us           0 b           0 b             1  \n",
      "                       aten::pow         0.70%     827.000us         0.71%     836.100us     167.220us     646.000us         0.50%     662.000us     132.400us     943.35 Kb     943.35 Kb             5  \n",
      "               aten::result_type         0.00%       5.300us         0.00%       5.300us       1.060us       9.000us         0.01%       9.000us       1.800us           0 b           0 b             5  \n",
      "                 aten::transpose         0.12%     138.200us         0.13%     156.700us      17.411us       1.836ms         1.43%       1.851ms     205.667us           0 b           0 b             9  \n",
      "                    aten::matmul         0.73%     860.100us         5.59%       6.578ms       6.578ms       1.213ms         0.94%       6.816ms       6.816ms      47.81 Kb           0 b             1  \n",
      "                    aten::expand         0.12%     139.600us         0.13%     149.700us      16.633us       1.225ms         0.95%       1.865ms     207.222us           0 b           0 b             9  \n",
      "                       aten::bmm         4.78%       5.626ms         4.78%       5.627ms       5.627ms       5.578ms         4.33%       5.581ms       5.581ms      47.81 Kb      47.81 Kb             1  \n",
      "              aten::resolve_conj         0.00%       4.800us         0.00%       4.800us       0.300us       1.234ms         0.96%       1.234ms      77.125us           0 b           0 b            16  \n",
      "              aten::_unsafe_view         0.02%      19.300us         0.02%      19.300us      19.300us       1.000us         0.00%       1.000us       1.000us           0 b           0 b             1  \n",
      "                       aten::add         1.21%       1.422ms         1.66%       1.949ms      97.475us       1.868ms         1.45%       4.440ms     222.000us       3.78 Mb       3.78 Mb            20  \n",
      "                  aten::_to_copy         0.47%     558.500us         0.58%     677.600us      48.400us       3.192ms         2.48%       3.846ms     274.714us          56 b           0 b            14  \n",
      "                       aten::log         0.85%       1.002ms         0.85%       1.002ms       1.002ms     766.000us         0.60%     766.000us     766.000us      47.81 Kb      47.81 Kb             1  \n",
      "                      aten::mean         0.43%     505.700us         1.67%       1.963ms     245.425us       2.476ms         1.92%       6.248ms     781.000us       2.67 Kb       2.65 Kb             8  \n",
      "                       aten::sum         0.62%     733.300us         0.65%     768.800us      76.880us       1.959ms         1.52%       1.979ms     197.900us       4.50 Kb       4.50 Kb            10  \n",
      "                     aten::fill_         0.03%      32.900us         0.03%      32.900us       3.290us      16.000us         0.01%      16.000us       1.600us           0 b           0 b            10  \n",
      "                      aten::div_         0.36%     423.600us         0.73%     854.000us     106.750us       1.227ms         0.95%       3.133ms     391.625us          16 b         -16 b             8  \n",
      "                       aten::sub         0.17%     197.700us         0.17%     197.700us      32.950us       1.232ms         0.96%       1.232ms     205.333us     950.06 Kb     950.06 Kb             6  \n",
      "                aten::contiguous         0.08%      98.700us         0.35%     415.000us     103.750us     624.000us         0.48%       1.273ms     318.250us     385.31 Kb           0 b             4  \n",
      "                     aten::clone         0.15%     180.000us         0.27%     316.300us      79.075us      22.000us         0.02%     649.000us     162.250us     385.31 Kb           0 b             4  \n",
      "               aten::thnn_conv2d         0.52%     608.500us         2.90%       3.413ms       1.706ms     609.000us         0.47%       1.858ms     929.000us     450.00 Kb           0 b             2  \n",
      "      aten::_slow_conv2d_forward         2.08%       2.452ms         2.38%       2.804ms       1.402ms     626.000us         0.49%       1.249ms     624.500us     450.00 Kb    -187.50 Kb             2  \n",
      "                      aten::sqrt         0.62%     726.000us         0.62%     726.000us     242.000us     619.000us         0.48%     619.000us     206.333us       3.42 Kb       3.42 Kb             3  \n",
      "                       aten::div         0.24%     284.900us         0.24%     284.900us      56.980us       9.000us         0.01%       9.000us       1.800us     459.00 Kb     459.00 Kb             5  \n",
      "                aten::layer_norm         0.17%     198.300us         1.42%       1.668ms     556.000us     597.000us         0.46%       3.724ms       1.241ms     341.02 Kb           0 b             3  \n",
      "         aten::native_layer_norm         0.96%       1.126ms         1.25%       1.470ms     489.900us       1.246ms         0.97%       3.127ms       1.042ms     341.02 Kb    -337.50 Kb             3  \n",
      "                    aten::linear         0.51%     595.800us         3.79%       4.461ms     637.229us       3.033ms         2.36%       9.320ms       1.331ms       1.65 Mb           0 b             7  \n",
      "                         aten::t         0.12%     145.000us         0.21%     248.200us      35.457us      24.000us         0.02%       1.263ms     180.429us           0 b           0 b             7  \n",
      "                     aten::addmm         2.67%       3.143ms         2.95%       3.469ms     495.643us      63.000us         0.05%       3.778ms     539.714us       1.65 Mb       1.65 Mb             7  \n",
      "                      aten::gelu         3.56%       4.188ms         3.56%       4.188ms       1.396ms       4.121ms         3.20%       4.121ms       1.374ms       1.32 Mb       1.32 Mb             3  \n",
      "        aten::linalg_vector_norm         0.88%       1.036ms         0.88%       1.036ms     345.233us     700.000us         0.54%     700.000us     233.333us       9.00 Kb       9.00 Kb             3  \n",
      "                       aten::cat         0.54%     635.500us         0.57%     673.200us     336.600us       4.000us         0.00%      12.000us       6.000us     342.00 Kb     342.00 Kb             2  \n",
      "                aten::batch_norm         0.17%     199.400us         1.87%       2.195ms     731.600us      10.000us         0.01%       2.598ms     866.000us      47.44 Kb           0 b             3  \n",
      "    aten::_batch_norm_impl_index         0.07%      86.800us         1.70%       1.995ms     665.133us      14.000us         0.01%       2.588ms     862.667us      47.44 Kb           0 b             3  \n",
      "         aten::native_batch_norm         1.55%       1.820ms         1.62%       1.903ms     634.267us       1.831ms         1.42%       1.867ms     622.333us      47.44 Kb     -11.06 Kb             3  \n",
      "                      aten::tanh         0.64%     747.900us         0.64%     747.900us     747.900us     623.000us         0.48%     623.000us     623.000us      42.19 Kb      42.19 Kb             1  \n",
      "                    aten::detach         0.00%       2.000us         0.00%       2.000us       2.000us       2.000us         0.00%       2.000us       2.000us           0 b           0 b             1  \n",
      "                   aten::softmax         0.12%     145.200us         0.54%     629.900us     629.900us       3.000us         0.00%       5.000us       5.000us     337.50 Kb           0 b             1  \n",
      "                  aten::_softmax         0.41%     484.700us         0.41%     484.700us     484.700us       2.000us         0.00%       2.000us       2.000us     337.50 Kb     337.50 Kb             1  \n",
      "                     aten::clamp         0.03%      39.100us         0.03%      39.500us      39.500us       4.000us         0.00%       5.000us       5.000us       2.25 Kb       2.25 Kb             1  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 117.645ms\n",
      "Self CUDA time total: 128.715ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwjln\\AppData\\Local\\Temp\\ipykernel_9852\\145856219.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load(r'C:\\Users\\jwjln\\Desktop\\SV\\SpeakerVerification\\experiments\\NeXt_TDNN_light_C192_B1_K65\\NeXt_TDNN_light_C192_B1_K65.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['feature_extractor.pre_emphasis.flipped_filter', 'feature_extractor.mel_spectrogram.spectrogram.window', 'feature_extractor.mel_spectrogram.mel_scale.fb', 'model.stages.0.0.dwconv.weight', 'model.stages.0.0.dwconv.bias', 'model.stages.0.0.norm.weight', 'model.stages.0.0.norm.bias', 'model.stages.0.0.pwconv1.weight', 'model.stages.0.0.pwconv1.bias', 'model.stages.0.0.grn.gamma', 'model.stages.0.0.grn.beta', 'model.stages.0.0.pwconv2.weight', 'model.stages.0.0.pwconv2.bias', 'model.stages.1.0.dwconv.weight', 'model.stages.1.0.dwconv.bias', 'model.stages.1.0.norm.weight', 'model.stages.1.0.norm.bias', 'model.stages.1.0.pwconv1.weight', 'model.stages.1.0.pwconv1.bias', 'model.stages.1.0.grn.gamma', 'model.stages.1.0.grn.beta', 'model.stages.1.0.pwconv2.weight', 'model.stages.1.0.pwconv2.bias', 'model.stages.2.0.dwconv.weight', 'model.stages.2.0.dwconv.bias', 'model.stages.2.0.norm.weight', 'model.stages.2.0.norm.bias', 'model.stages.2.0.pwconv1.weight', 'model.stages.2.0.pwconv1.bias', 'model.stages.2.0.grn.gamma', 'model.stages.2.0.grn.beta', 'model.stages.2.0.pwconv2.weight', 'model.stages.2.0.pwconv2.bias', 'model.MFA.0.weight', 'model.MFA.0.bias', 'model.MFA.1.weight', 'model.MFA.1.bias', 'aggregate.conv_1.weight', 'aggregate.conv_1.bias', 'aggregate.conv_2.weight', 'aggregate.conv_2.bias', 'aggregate.bn1.weight', 'aggregate.bn1.bias', 'aggregate.bn1.running_mean', 'aggregate.bn1.running_var', 'aggregate.bn2.weight', 'aggregate.bn2.bias', 'aggregate.bn2.running_mean', 'aggregate.bn2.running_var', 'aggregate.fc.weight', 'aggregate.fc.bias', 'aggregate.bn3.weight', 'aggregate.bn3.bias', 'aggregate.bn3.running_mean', 'aggregate.bn3.running_var', 'loss_function.weight'], unexpected_keys=['speaker_net.feature_extractor.pre_emphasis.flipped_filter', 'speaker_net.feature_extractor.mel_spectrogram.spectrogram.window', 'speaker_net.feature_extractor.mel_spectrogram.mel_scale.fb', 'speaker_net.model.stages.0.0.dwconv.weight', 'speaker_net.model.stages.0.0.dwconv.bias', 'speaker_net.model.stages.0.0.norm.weight', 'speaker_net.model.stages.0.0.norm.bias', 'speaker_net.model.stages.0.0.pwconv1.weight', 'speaker_net.model.stages.0.0.pwconv1.bias', 'speaker_net.model.stages.0.0.grn.gamma', 'speaker_net.model.stages.0.0.grn.beta', 'speaker_net.model.stages.0.0.pwconv2.weight', 'speaker_net.model.stages.0.0.pwconv2.bias', 'speaker_net.model.stages.1.0.dwconv.weight', 'speaker_net.model.stages.1.0.dwconv.bias', 'speaker_net.model.stages.1.0.norm.weight', 'speaker_net.model.stages.1.0.norm.bias', 'speaker_net.model.stages.1.0.pwconv1.weight', 'speaker_net.model.stages.1.0.pwconv1.bias', 'speaker_net.model.stages.1.0.grn.gamma', 'speaker_net.model.stages.1.0.grn.beta', 'speaker_net.model.stages.1.0.pwconv2.weight', 'speaker_net.model.stages.1.0.pwconv2.bias', 'speaker_net.model.stages.2.0.dwconv.weight', 'speaker_net.model.stages.2.0.dwconv.bias', 'speaker_net.model.stages.2.0.norm.weight', 'speaker_net.model.stages.2.0.norm.bias', 'speaker_net.model.stages.2.0.pwconv1.weight', 'speaker_net.model.stages.2.0.pwconv1.bias', 'speaker_net.model.stages.2.0.grn.gamma', 'speaker_net.model.stages.2.0.grn.beta', 'speaker_net.model.stages.2.0.pwconv2.weight', 'speaker_net.model.stages.2.0.pwconv2.bias', 'speaker_net.model.MFA.0.weight', 'speaker_net.model.MFA.0.bias', 'speaker_net.model.MFA.1.weight', 'speaker_net.model.MFA.1.bias', 'speaker_net.aggregate.conv_1.weight', 'speaker_net.aggregate.conv_1.bias', 'speaker_net.aggregate.conv_2.weight', 'speaker_net.aggregate.conv_2.bias', 'speaker_net.aggregate.bn1.weight', 'speaker_net.aggregate.bn1.bias', 'speaker_net.aggregate.bn1.running_mean', 'speaker_net.aggregate.bn1.running_var', 'speaker_net.aggregate.bn1.num_batches_tracked', 'speaker_net.aggregate.bn2.weight', 'speaker_net.aggregate.bn2.bias', 'speaker_net.aggregate.bn2.running_mean', 'speaker_net.aggregate.bn2.running_var', 'speaker_net.aggregate.bn2.num_batches_tracked', 'speaker_net.aggregate.fc.weight', 'speaker_net.aggregate.fc.bias', 'speaker_net.aggregate.bn3.weight', 'speaker_net.aggregate.bn3.bias', 'speaker_net.aggregate.bn3.running_mean', 'speaker_net.aggregate.bn3.running_var', 'speaker_net.aggregate.bn3.num_batches_tracked'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original\n",
    "dic = torch.load('./experiments/NeXt_TDNN_light_C192_B1_K65/NeXt_TDNN_light_C192_B1_K65.pt')\n",
    "speaker_net.load_state_dict(dic['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50700/50700 [03:47<00:00, 222.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine EER : 36.34319526627219, Euclidean EER : 36.34319526627219\n",
      "Cosine MinDCF : 0.9282445759368835, Euclidean MinDCF : 0.9282445759368835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwjln\\AppData\\Local\\Temp\\ipykernel_7364\\821997797.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load('./experiments/K_NeXt_TDNN/ckpt_5.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knext\n",
    "dic = torch.load('./experiments/K_NeXt_TDNN/ckpt_5.pt')\n",
    "speaker_net.load_state_dict(dic['model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50700/50700 [15:14<00:00, 55.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine EER : 11.44378698224852, Euclidean EER : 11.44378698224852\n",
      "Cosine MinDCF : 0.4206311637080868, Euclidean MinDCF : 0.4206311637080868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_eer, euc_eer, cos_dcf, euc_dcf = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "print('Cosine MinDCF : {0}, Euclidean MinDCF : {1}'.format(cos_dcf, euc_dcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001005411148071289\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from eval import *\n",
    "\n",
    "test_audio_file = 'KHOtest.wav' ####\n",
    "\n",
    "speaker_net.eval()\n",
    "test_audio = load_audio(test_audio_file, DEVICE)\n",
    "\n",
    "start = time.time()\n",
    "test_emb = speaker_net(test_audio.unsqueeze(0))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import data.kdataset as kdataset\n",
    "\n",
    "print('Load train dataset..')\n",
    "asv_dataset = kdataset.asv_dataset(*config['TRAIN_DATASET'].values())\n",
    "\n",
    "#train_dataset, validation_dataset = random_split(asv_dataset, [0.9, 0.1])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    asv_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = NUM_WORKER,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "             record_shapes=True, profile_memory=True, on_trace_ready=torch.profiler.tensorboard_trace_handler('./tboard/tdnn')) as prof:\n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        losses = 0\n",
    "        \n",
    "        speaker_net.train()\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print('=== Epoch : {0} ==='.format(epoch))\n",
    "        pbar = tqdm.tqdm(train_loader)\n",
    "        for idx, (x, y) in enumerate(pbar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            spk_emb = speaker_net(x.to(DEVICE))\n",
    "            loss, _ = loss_function(spk_emb, y.to(DEVICE))\n",
    "            losses += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if idx % 1000 == 0:\n",
    "                pbar.set_postfix_str('{0} step loss : {1}'.format(idx, loss))\n",
    "        \n",
    "    scheduler.step()\n",
    "    print('-- Epoch {0} loss : {1}'.format(epoch, losses/len(train_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
