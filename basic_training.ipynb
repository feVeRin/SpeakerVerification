{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import data.kdataset as kdataset\n",
    "from SpeakerNet import SpeakerNet\n",
    "from util import *\n",
    "import gc\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/K_NeXt_TDNN.yaml') as file:\n",
    "#with open('toy.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "BATCH_SIZE = config['PARAMS']['BATCH_SIZE']\n",
    "BASE_LR = float(config['PARAMS']['BASE_LR'])\n",
    "NUM_WORKER = config['PARAMS']['NUM_WORKER']\n",
    "CHANNEL_SIZE = config['PARAMS']['CHANNEL_SIZE']\n",
    "EMBEDDING_SIZE = config['PARAMS']['EMBEDDING_SIZE']\n",
    "MAX_FRAME = config['PARAMS']['MAX_FRAME']\n",
    "SAMPLING_RATE = config['PARAMS']['SAMPLING_RATE']\n",
    "MAX_EPOCH = config['PARAMS']['MAX_EPOCH']\n",
    "DEVICE = config['PARAMS']['DEVICE']\n",
    "BASE_PATH = config['PARAMS']['BASE_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Train Dataset...\n",
      "Read pkl...\n",
      "\n",
      "====== Dataset Load Info ======\n",
      "Number of speakers : 1471\n",
      "Number of utterances : 5875802\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5875802 entries, 0 to 5875801\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   wavfiles  object\n",
      " 1   labels    int64 \n",
      " 2   speakers  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 134.5+ MB\n",
      "None\n",
      "===============================\n",
      "\n",
      "Setting Model...\n",
      "Initialised AAMSoftmax margin 0.300 scale 40.000\n",
      "⚡ feature_extractor ⚡\n",
      "Mel_Spectrogram(\n",
      "  (pre_emphasis): PreEmphasis()\n",
      "  (mel_spectrogram): MelSpectrogram(\n",
      "    (spectrogram): Spectrogram()\n",
      "    (mel_scale): MelScale()\n",
      "  )\n",
      ")\n",
      "⚡ spec_aug ⚡\n",
      "SpecAugment(\n",
      "  (fm): FrequencyMasking()\n",
      "  (tm): TimeMasking()\n",
      ")\n",
      "⚡ model ⚡\n",
      "NeXtTDNN(\n",
      "  (stem): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(80, 192, kernel_size=(4,), stride=(1,))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): TSConvNeXt_light(\n",
      "        (dwconv): Conv1d(192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (grn): GRN()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (MFA): Sequential(\n",
      "    (0): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      "    (1): LayerNorm()\n",
      "  )\n",
      ")\n",
      "⚡ aggregation ⚡\n",
      "VAP_BN_FC_BN(\n",
      "  (conv_1): Conv1d(576, 72, kernel_size=(1,), stride=(1,))\n",
      "  (conv_2): Conv1d(72, 576, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (tanh): Tanh()\n",
      "  (bn2): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=1152, out_features=192, bias=True)\n",
      "  (bn3): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "⚡ loss ⚡\n",
      "LossFunction(\n",
      "  (ce): CrossEntropyLoss()\n",
      ")\n",
      "Initialised AdamW optimizer\n",
      "Initialised step LR scheduler\n",
      "===============================\n",
      "\n",
      "Model Summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jwjln\\Desktop\\SV\\SpeakerVerification\\train.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(config['CHECKPOINT']['ckpt_path'], ckpt_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerNet(\n",
      "  1.63 M, 84.888% Params, 420.52 MMac, 98.346% MACs, \n",
      "  (feature_extractor): Mel_Spectrogram(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (pre_emphasis): PreEmphasis(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (mel_spectrogram): MelSpectrogram(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (spectrogram): Spectrogram(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (mel_scale): MelScale(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (spec_aug): SpecAugment(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (fm): FrequencyMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (tm): TimeMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (model): NeXtTDNN(\n",
      "    1.32 M, 68.832% Params, 395.25 MMac, 92.439% MACs, \n",
      "    (stem): ModuleList(\n",
      "      (0): Sequential(\n",
      "        61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, \n",
      "        (0): Conv1d(61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, 80, 192, kernel_size=(4,), stride=(1,))\n",
      "        (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (stages): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "        (0): TSConvNeXt_light(\n",
      "          308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "          (dwconv): Conv1d(12.67 k, 0.661% Params, 3.79 MMac, 0.886% MACs, 192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "          (norm): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv1): Linear(148.22 k, 7.732% Params, 44.32 MMac, 10.365% MACs, in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(0, 0.000% Params, 229.63 KMac, 0.054% MACs, approximate='none')\n",
      "          (grn): GRN(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv2): Linear(147.65 k, 7.701% Params, 44.15 MMac, 10.325% MACs, in_features=768, out_features=192, bias=True)\n",
      "          (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (MFA): Sequential(\n",
      "      332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, \n",
      "      (0): Conv1d(332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, 576, 576, kernel_size=(1,), stride=(1,))\n",
      "      (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (aggregate): VAP_BN_FC_BN(\n",
      "    307.8 k, 16.055% Params, 25.26 MMac, 5.908% MACs, \n",
      "    (conv_1): Conv1d(41.54 k, 2.167% Params, 12.42 MMac, 2.905% MACs, 576, 72, kernel_size=(1,), stride=(1,))\n",
      "    (conv_2): Conv1d(42.05 k, 2.193% Params, 12.57 MMac, 2.940% MACs, 72, 576, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(144, 0.008% Params, 43.06 KMac, 0.010% MACs, 72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (tanh): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (bn2): BatchNorm1d(2.3 k, 0.120% Params, 2.3 KMac, 0.001% MACs, 1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): Linear(221.38 k, 11.547% Params, 221.38 KMac, 0.052% MACs, in_features=1152, out_features=192, bias=True)\n",
      "    (bn3): BatchNorm1d(384, 0.020% Params, 384.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (loss_function): LossFunction(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (ce): CrossEntropyLoss(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "ptflops: MMac: 427.59, Params: 1.92\n",
      "thop: MMac: 418.415136, Params: 1.627416\n",
      "torchinfo: MMac: 155.27652, Params: 1.917144\n",
      "===============================\n",
      "\n",
      "Model Training...\n",
      "Load Previous Checkpoint..\n",
      "=== Epoch : 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1395/11476 [3:14:41<23:27:30,  8.38s/it, 1000 step loss : 6.088515281677246]"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "ckpt_name = 'ckpt_5.pt'\n",
    "train(config, MAX_EPOCH, BATCH_SIZE, NUM_WORKER, BASE_LR, BASE_PATH, DEVICE, ckpt=True, ckpt_name=ckpt_name)\n",
    "#train(config, MAX_EPOCH, BATCH_SIZE, NUM_WORKER, BASE_LR, BASE_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train dataset..\n",
      "Read pkl...\n",
      "\n",
      "====== Dataset Load Info ======\n",
      "Number of speakers : 1471\n",
      "Number of utterances : 5875802\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5875802 entries, 0 to 5875801\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   wavfiles  object\n",
      " 1   labels    int64 \n",
      " 2   speakers  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 134.5+ MB\n",
      "None\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "print('Load train dataset..')\n",
    "asv_dataset = kdataset.asv_dataset(*config['TRAIN_DATASET'].values())\n",
    "\n",
    "#train_dataset, validation_dataset = random_split(asv_dataset, [0.9, 0.1])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    asv_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = NUM_WORKER,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised AAMSoftmax margin 0.300 scale 40.000\n",
      "⚡ feature_extractor ⚡\n",
      "Mel_Spectrogram(\n",
      "  (pre_emphasis): PreEmphasis()\n",
      "  (mel_spectrogram): MelSpectrogram(\n",
      "    (spectrogram): Spectrogram()\n",
      "    (mel_scale): MelScale()\n",
      "  )\n",
      ")\n",
      "⚡ spec_aug ⚡\n",
      "SpecAugment(\n",
      "  (fm): FrequencyMasking()\n",
      "  (tm): TimeMasking()\n",
      ")\n",
      "⚡ model ⚡\n",
      "NeXtTDNN(\n",
      "  (stem): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(80, 192, kernel_size=(4,), stride=(1,))\n",
      "      (1): LayerNorm()\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0-2): 3 x Sequential(\n",
      "      (0): TSConvNeXt_light(\n",
      "        (dwconv): Conv1d(192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "        (norm): LayerNorm()\n",
      "        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (grn): GRN()\n",
      "        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (MFA): Sequential(\n",
      "    (0): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      "    (1): LayerNorm()\n",
      "  )\n",
      ")\n",
      "⚡ aggregation ⚡\n",
      "VAP_BN_FC_BN(\n",
      "  (conv_1): Conv1d(576, 72, kernel_size=(1,), stride=(1,))\n",
      "  (conv_2): Conv1d(72, 576, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (tanh): Tanh()\n",
      "  (bn2): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=1152, out_features=192, bias=True)\n",
      "  (bn3): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "⚡ loss ⚡\n",
      "LossFunction(\n",
      "  (ce): CrossEntropyLoss()\n",
      ")\n",
      "Initialised AdamW optimizer\n",
      "Initialised step LR scheduler\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = importlib.import_module('preprocessing.mel_transform').__getattribute__(\"feature_extractor\")\n",
    "feature_extractor = feature_extractor(*config['FEATURE_EXTRACTOR'].values()).to(DEVICE)\n",
    "\n",
    "#fe = feature_extractor(x.to(DEVICE))\n",
    "#print('feature extractor :', fe.shape)\n",
    "\n",
    "spec_aug = importlib.import_module('preprocessing.spec_aug').__getattribute__(\"spec_aug\")\n",
    "spec_aug = spec_aug(*config['SPEC_AUG'].values()).to(DEVICE)\n",
    "\n",
    "#sa = spec_aug(fe)\n",
    "#print('spec aug :', sa.shape)\n",
    "\n",
    "model_cfg = config['MODEL']\n",
    "model = importlib.import_module('models.NeXt_TDNN').__getattribute__(\"MainModel\")\n",
    "model =  model(\n",
    "    depths = model_cfg['depths'], \n",
    "    dims = model_cfg['dims'],\n",
    "    kernel_size = model_cfg['kernel_size'],\n",
    "    block = model_cfg['block']\n",
    ").to(DEVICE)\n",
    "\n",
    "#m = model(sa.to(DEVICE))\n",
    "#print('model :', m.shape)\n",
    "\n",
    "aggregation = importlib.import_module('aggregation.vap_bn_tanh_fc_bn').__getattribute__(\"Aggregation\")\n",
    "aggregation = aggregation(*config['AGGREGATION'].values()).to(DEVICE)\n",
    "\n",
    "#a = aggregation(m).to(DEVICE)\n",
    "#print('aggregation : ', a.shape)\n",
    "\n",
    "loss_function = importlib.import_module(\"loss.aamsoftmax\").__getattribute__(\"LossFunction\")\n",
    "loss_function = loss_function(*config['LOSS'].values())\n",
    "\n",
    "speaker_net = SpeakerNet(feature_extractor = feature_extractor,\n",
    "                       spec_aug = spec_aug, \n",
    "                       model = model,\n",
    "                       aggregation=aggregation,\n",
    "                       loss_function = loss_function).to(DEVICE)\n",
    "\n",
    "optimizer = importlib.import_module(\"optimizer.\" + 'adamw').__getattribute__(\"Optimizer\")\n",
    "optimizer = optimizer(speaker_net.parameters(), lr= BASE_LR*BATCH_SIZE, weight_decay = 0.01,)    \n",
    "\n",
    "scheduler = importlib.import_module(\"scheduler.\" + 'steplr').__getattribute__(\"Scheduler\")\n",
    "scheduler = scheduler(optimizer, step_size = 10, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeakerNet(\n",
      "  1.63 M, 84.888% Params, 420.52 MMac, 98.346% MACs, \n",
      "  (feature_extractor): Mel_Spectrogram(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (pre_emphasis): PreEmphasis(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (mel_spectrogram): MelSpectrogram(\n",
      "      0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "      (spectrogram): Spectrogram(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (mel_scale): MelScale(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (spec_aug): SpecAugment(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (fm): FrequencyMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (tm): TimeMasking(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      "  (model): NeXtTDNN(\n",
      "    1.32 M, 68.832% Params, 395.25 MMac, 92.439% MACs, \n",
      "    (stem): ModuleList(\n",
      "      (0): Sequential(\n",
      "        61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, \n",
      "        (0): Conv1d(61.63 k, 3.215% Params, 18.43 MMac, 4.310% MACs, 80, 192, kernel_size=(4,), stride=(1,))\n",
      "        (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      )\n",
      "    )\n",
      "    (stages): ModuleList(\n",
      "      (0-2): 3 x Sequential(\n",
      "        308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "        (0): TSConvNeXt_light(\n",
      "          308.54 k, 16.094% Params, 92.48 MMac, 21.629% MACs, \n",
      "          (dwconv): Conv1d(12.67 k, 0.661% Params, 3.79 MMac, 0.886% MACs, 192, 192, kernel_size=(65,), stride=(1,), padding=(32,), groups=192)\n",
      "          (norm): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv1): Linear(148.22 k, 7.732% Params, 44.32 MMac, 10.365% MACs, in_features=192, out_features=768, bias=True)\n",
      "          (act): GELU(0, 0.000% Params, 229.63 KMac, 0.054% MACs, approximate='none')\n",
      "          (grn): GRN(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "          (pwconv2): Linear(147.65 k, 7.701% Params, 44.15 MMac, 10.325% MACs, in_features=768, out_features=192, bias=True)\n",
      "          (drop_path): Identity(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (MFA): Sequential(\n",
      "      332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, \n",
      "      (0): Conv1d(332.35 k, 17.336% Params, 99.37 MMac, 23.241% MACs, 576, 576, kernel_size=(1,), stride=(1,))\n",
      "      (1): LayerNorm(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    )\n",
      "  )\n",
      "  (aggregate): VAP_BN_FC_BN(\n",
      "    307.8 k, 16.055% Params, 25.26 MMac, 5.908% MACs, \n",
      "    (conv_1): Conv1d(41.54 k, 2.167% Params, 12.42 MMac, 2.905% MACs, 576, 72, kernel_size=(1,), stride=(1,))\n",
      "    (conv_2): Conv1d(42.05 k, 2.193% Params, 12.57 MMac, 2.940% MACs, 72, 576, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(144, 0.008% Params, 43.06 KMac, 0.010% MACs, 72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (tanh): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (bn2): BatchNorm1d(2.3 k, 0.120% Params, 2.3 KMac, 0.001% MACs, 1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc): Linear(221.38 k, 11.547% Params, 221.38 KMac, 0.052% MACs, in_features=1152, out_features=192, bias=True)\n",
      "    (bn3): BatchNorm1d(384, 0.020% Params, 384.0 Mac, 0.000% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (loss_function): LossFunction(\n",
      "    0, 0.000% Params, 0.0 Mac, 0.000% MACs, \n",
      "    (ce): CrossEntropyLoss(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "  )\n",
      ")\n",
      "ptflops: MMac: 427.59, Params: 1.92\n",
      "thop: MMac: 418.415136, Params: 1.627416\n",
      "torchinfo: MMac: 155.27652, Params: 1.917144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('427.59', '1.92', 418.415136, 1.627416, 155.27652, 1.917144)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하지말것 cpu 이동됨\n",
    "get_model_param_mmac(speaker_net, int(160*300 + 240), DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_metric import compute_eer\n",
    "from backend.cosine_similarity_full import cosine_similarity_full\n",
    "from backend.euclidean_distance_full import euclidean_distance_full\n",
    "import soundfile as sf\n",
    "import tqdm\n",
    "\n",
    "def make_enrollment(gt_model, enr_df_path, base_df):\n",
    "    enr_list = []\n",
    "    enr_path = os.path.join(enr_df_path, 'enr_df.pkl')\n",
    "    \n",
    "    label_list = base_df.labels.unique()\n",
    "    \n",
    "    enr_df = pd.DataFrame()\n",
    "    for label in tqdm.tqdm(label_list):\n",
    "        #wavquery = base_df.query(\"labels == {0}\".format(label)).iloc[0]\n",
    "        #enr_wav, _ = sf.read(wavquery['wavfiles'])\n",
    "        \n",
    "        #enr_x = torch.FloatTensor(enr_wav).to(device)\n",
    "        #enr_emb = gt_model(enr_x.unsqueeze(0))\n",
    "        #wavquery['enr_emb'] = enr_emb.detach().cpu()\n",
    "        \n",
    "        cohorts = []\n",
    "        for i in range(50):\n",
    "            wavquery = base_df.query('labels == {0}'.format(label)).iloc[0]\n",
    "            if i%2 == 0:\n",
    "                cohort = base_df.query('labels == {0}'.format(label)).sample().wavfiles.values[0]\n",
    "                cohort_label = 1\n",
    "            else:\n",
    "                cohort = base_df.query('labels != {0}'.format(label)).sample().wavfiles.values[0]\n",
    "                cohort_label = 0\n",
    "            wavquery['cohort'] = cohort\n",
    "            wavquery['cohort_label'] = cohort_label\n",
    "            cohorts.append(wavquery)\n",
    "        cohort_df = pd.DataFrame(cohorts)\n",
    "        enr_df = pd.concat([enr_df, cohort_df], ignore_index=True)\n",
    "    \n",
    "    enr_df.to_pickle(enr_path)\n",
    "    \n",
    "    del base_df\n",
    "    del enr_list\n",
    "    del label_list\n",
    "    del gt_model\n",
    "    del cohort_df\n",
    "    \n",
    "    return enr_df\n",
    "\n",
    "def validation(model, base_path, device):\n",
    "    model.eval()\n",
    "    \n",
    "    cos_sim_list = []\n",
    "    euc_dist_list = []\n",
    "    valid_label = []\n",
    "    \n",
    "    if os.path.isfile(os.path.join(base_path, 'enr_df.pkl')):\n",
    "        enr_df = pd.read_pickle(os.path.join(base_path, 'enr_df.pkl'))\n",
    "    else:\n",
    "        base_df = pd.read_pickle(os.path.join(base_path, 'train_df.pkl'))\n",
    "        enr_df = make_enrollment(model, base_path, base_df)\n",
    "        \n",
    "        del base_df\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #for idx, (x, y) in enumerate(loader):\n",
    "        for _, row in enr_df.iterrows():\n",
    "            enr_x, _ = sf.read(row['wavfiles'])\n",
    "            enr_x = torch.FloatTensor(enr_x)\n",
    "            enr_emb = model(enr_x.unsqueeze(0).to(device))\n",
    "            \n",
    "            spk_x, _ = sf.read(row['cohort'])\n",
    "            spk_x = torch.FloatTensor(enr_x)\n",
    "            spk_emb = model(spk_x.unsqueeze(0).to(device))\n",
    "            \n",
    "            valid_label.append(row['cohort_label'])\n",
    "            #enr_emb = enr_df.query(\"labels == {0}\".format(int(y)))['enr_emb'].values[0]\n",
    "            #enr_x = enr_df.query(\"labels == {0}\".format(row[]))\n",
    "            #enr_emb = model(enr_x.to(device))\n",
    "            #for yy in y:\n",
    "            #    enr_emb.append(enr_df.query(\"labels == {0}\".format(yy))['enr_emb'].values[0])\n",
    "            #spk_emb = model(x.to(device))\n",
    "        \n",
    "            # cosine similarity\n",
    "            #cos_sim = cosine_similarity_full(torch.stack(enr_emb).squeeze(1), spk_emb.detach().cpu())\n",
    "            cos_sim = cosine_similarity_full(enr_emb, spk_emb)\n",
    "            cos_sim_list.append(cos_sim.detach().cpu().numpy())\n",
    "        \n",
    "            # Euclidean\n",
    "            #cos_sim = euclidean_distance_full(torch.stack(enr_emb).squeeze(1), spk_emb.detach().cpu())\n",
    "            cos_sim = euclidean_distance_full(enr_emb, spk_emb)\n",
    "            euc_dist_list.append(cos_sim.detach().cpu().numpy())\n",
    "        \n",
    "    # EER\n",
    "    cos_eer, _ = compute_eer(cos_sim_list, valid_label)\n",
    "    euc_eer, _ = compute_eer(euc_dist_list, valid_label)\n",
    "    \n",
    "    del enr_df\n",
    "    del cos_sim_list\n",
    "    del euc_dist_list\n",
    "    del valid_label\n",
    "    \n",
    "    return cos_eer, euc_eer\n",
    "\n",
    "# unique speaker를 추출해서 enrollment 파일을 만들고\n",
    "# enrollment wav와 spk_emb를 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training..\n",
      "\n",
      "=== Epoch : 0 ===\n",
      "0 step loss : 23.00664520263672\n",
      "100 step loss : 18.883506774902344\n",
      "200 step loss : 18.5505313873291\n",
      "300 step loss : 18.00434684753418\n",
      "400 step loss : 17.644161224365234\n",
      "500 step loss : 17.54828643798828\n",
      "600 step loss : 17.274524688720703\n",
      "700 step loss : 16.927719116210938\n",
      "800 step loss : 17.214963912963867\n",
      "900 step loss : 16.62836265563965\n",
      "1000 step loss : 16.54280662536621\n",
      "1100 step loss : 16.301109313964844\n",
      "1200 step loss : 16.11001968383789\n",
      "1300 step loss : 15.71225643157959\n",
      "1400 step loss : 15.703887939453125\n",
      "1500 step loss : 15.203147888183594\n",
      "1600 step loss : 15.463879585266113\n",
      "1700 step loss : 14.993700981140137\n",
      "1800 step loss : 14.833720207214355\n",
      "1900 step loss : 14.880380630493164\n",
      "2000 step loss : 14.52582836151123\n",
      "2100 step loss : 15.052695274353027\n",
      "2200 step loss : 14.097025871276855\n",
      "2300 step loss : 14.471131324768066\n",
      "2400 step loss : 13.708948135375977\n",
      "2500 step loss : 13.32651424407959\n",
      "2600 step loss : 14.166337013244629\n",
      "2700 step loss : 13.629612922668457\n",
      "2800 step loss : 13.980696678161621\n",
      "2900 step loss : 13.766913414001465\n",
      "3000 step loss : 13.23370361328125\n",
      "3100 step loss : 12.944464683532715\n",
      "3200 step loss : 12.812379837036133\n",
      "3300 step loss : 13.133642196655273\n",
      "3400 step loss : 12.397573471069336\n",
      "3500 step loss : 13.037261009216309\n",
      "3600 step loss : 12.75179672241211\n",
      "3700 step loss : 11.900077819824219\n",
      "3800 step loss : 12.385351181030273\n",
      "3900 step loss : 12.322698593139648\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=== Epoch : \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1324\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\torch\\_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'TypeError'>, TypeError('an integer is required'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2179\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2176\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m   2177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\ipykernel\\zmqshell.py:559\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[1;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[0;32m    553\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    556\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    562\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\soundfile.py:1601\u001b[0m, in \u001b[0;36mLibsndfileError.__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_string\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\new\\Lib\\site-packages\\soundfile.py:1592\u001b[0m, in \u001b[0;36mLibsndfileError.error_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raw libsndfile error message.\"\"\"\u001b[39;00m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode:\n\u001b[1;32m-> 1592\u001b[0m     err_str \u001b[38;5;241m=\u001b[39m \u001b[43m_snd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msf_error_number\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ffi\u001b[38;5;241m.\u001b[39mstring(err_str)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# Due to race conditions, if used concurrently, sf_error() may\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;66;03m# return 0 (= no error) even if an error has happened.\u001b[39;00m\n\u001b[0;32m   1597\u001b[0m     \u001b[38;5;66;03m# See https://github.com/erikd/libsndfile/issues/610 for details.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "print('Model Training..')\n",
    "print()\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    losses = 0\n",
    "    \n",
    "    speaker_net.train()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('=== Epoch : {0} ==='.format(epoch))\n",
    "    for idx, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        spk_emb = speaker_net(x.to(DEVICE))\n",
    "        loss, _ = loss_function(spk_emb, y.to(DEVICE))\n",
    "        losses += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 100 ==0:\n",
    "            print('{0} step loss : {1}'.format(idx, loss))\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('-- Epoch {0} loss : {1}'.format(epoch, losses/len(train_loader)))\n",
    "    \n",
    "    # validation\n",
    "    cos_eer, euc_eer = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "    print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "    \n",
    "    ckpt_name = config['CHECKPOINT']['filename'].format(epoch)\n",
    "    torch.save({'epoch' : epoch,\n",
    "                'model' : speaker_net.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'scheduler' : scheduler.state_dict(),\n",
    "                'loss' : losses/len(train_loader),\n",
    "                'cos_eer' : cos_eer,\n",
    "                'euc_eer' : euc_eer,\n",
    "                }, os.path.join(config['CHECKPOINT']['ckpt_path'], ckpt_name))\n",
    "    print('-- Epoch {0} ckpt saved..'.format(epoch))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwjln\\AppData\\Local\\Temp\\ipykernel_15448\\3758792550.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(config['CHECKPOINT']['ckpt_path'], ckpt_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch : 2 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=== Epoch : \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m     spk_emb \u001b[38;5;241m=\u001b[39m speaker_net(x\u001b[38;5;241m.\u001b[39mto(DEVICE))\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[0;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\jwjln\\anaconda3\\envs\\real\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 이어서 하기\n",
    "ckpt_name = 'ckpt_1.pt'\n",
    "checkpoint = torch.load(os.path.join(config['CHECKPOINT']['ckpt_path'], ckpt_name))\n",
    "speaker_net.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "for epoch in range(checkpoint_epoch+1, MAX_EPOCH):\n",
    "    losses = 0\n",
    "    \n",
    "    speaker_net.train()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('=== Epoch : {0} ==='.format(epoch))\n",
    "    for idx, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        spk_emb = speaker_net(x.to(DEVICE))\n",
    "        loss, _ = loss_function(spk_emb, y.to(DEVICE))\n",
    "        losses += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 100 ==0:\n",
    "            print('{0} step loss : {1}'.format(idx, loss))\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('-- Epoch {0} loss : {1}'.format(epoch, losses/len(train_loader)))\n",
    "    \n",
    "    # validation\n",
    "    cos_eer, euc_eer = validation(speaker_net, BASE_PATH, DEVICE)\n",
    "    print('Cosine EER : {0}, Euclidean EER : {1}'.format(cos_eer, euc_eer))\n",
    "    \n",
    "    ckpt_name = config['CHECKPOINT']['filename'].format(epoch)\n",
    "    torch.save({'epoch' : epoch,\n",
    "                'model' : speaker_net.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'scheduler' : scheduler.state_dict(),\n",
    "                'loss' : losses/len(train_loader),\n",
    "                'cos_eer' : cos_eer,\n",
    "                'euc_eer' : euc_eer,\n",
    "                }, os.path.join(config['CHECKPOINT']['ckpt_path'], ckpt_name))\n",
    "    print('-- Epoch {0} ckpt saved..'.format(epoch))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read pkl...\n",
      "\n",
      "====== Dataset Load Info ======\n",
      "Number of speakers : 2\n",
      "Number of utterances : 278\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   wavfiles  278 non-null    object\n",
      " 1   labels    278 non-null    int64 \n",
      " 2   speakers  278 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 6.6+ KB\n",
      "None\n",
      "===============================\n",
      "torch.Size([1, 39200])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = kdataset.asv_dataset(*config['TEST_DATASET'].values())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 1,\n",
    "    num_workers = 4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for idx, (x, label) in enumerate(test_loader):\n",
    "    if idx==0:\n",
    "        break\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speaker_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mspeaker_net\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader): \u001b[38;5;66;03m#test_loader\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speaker_net' is not defined"
     ]
    }
   ],
   "source": [
    "speaker_net.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(test_loader): #test_loader\n",
    "        spk_emb = speaker_net(x)\n",
    "        _, acc = loss_function(spk_emb, y)\n",
    "        if idx % 50 == 0:\n",
    "            print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single Wav file inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference with wav file\n",
    "import soundfile as sf\n",
    "audio, sr = sf.read('B0001-0001M1113-2__000_0-00200760.wav')\n",
    "audio = torch.FloatTensor(audio)\n",
    "test_audio = audio.unsqueeze(dim=0)\n",
    "\n",
    "speaker_net.eval()\n",
    "out = speaker_net(test_audio)\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
